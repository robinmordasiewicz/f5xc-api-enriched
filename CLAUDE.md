# CLAUDE.md - AI Assistant Instructions

This document provides Claude Code with the context and patterns needed to work effectively with the F5 XC API Enriched codebase.

## Project Overview

**Purpose**: Automated enrichment pipeline for F5 Distributed Cloud OpenAPI specifications.

**Architecture Principles**:

- **Two-Folder Architecture**: Source specs (gitignored) → Generated output (gitignored, served by GitHub Pages)
- **ETag-Based Caching**: Bandwidth optimization preventing redundant downloads
- **Deterministic Output**: Same input always produces identical output
- **Semantic Versioning**: Automatic version bumping based on change detection

## Directory Structure

```text
f5xc-api-enriched/
├── specs/
│   ├── original/           # READ-ONLY - Downloaded from F5 (gitignored)
│   └── discovered/         # API discovery output
│       ├── openapi.json    # Full discovery spec (25MB, tracked in git)
│       └── session.json    # Discovery session metadata
├── docs/
│   ├── specifications/api/ # Generated specs (gitignored, GitHub Pages)
│   │   ├── *.json          # Domain-specific specs
│   │   ├── openapi.json    # Master combined spec
│   │   └── index.json      # Metadata index
│   ├── scalar/             # Scalar API documentation UI
│   └── swagger-ui/         # Swagger UI documentation
├── scripts/                # Python pipeline scripts
│   ├── pipeline.py         # Main unified pipeline
│   ├── download.py         # ETag-cached spec download
│   ├── enrich.py           # Enrichment (branding, grammar)
│   ├── normalize.py        # Normalization (refs, types)
│   ├── merge_specs.py      # Domain merging
│   ├── discover.py         # Live API discovery
│   ├── lint.py             # Spectral OpenAPI linting
│   ├── validate.py         # Live API validation
│   └── analyze_constraints.py  # Discovery constraint analysis
├── config/
│   ├── enrichment.yaml          # Enrichment rules
│   ├── normalization.yaml       # Normalization rules
│   ├── discovery.yaml           # Discovery configuration
│   ├── server_variables.yaml    # 6 OpenAPI server variables (multi-env support)
│   ├── minimum_configs.yaml     # CLI metadata for 5 priority resources (Issue #152)
│   ├── default_minimum_configs.yaml  # Default templates for auto-generation
│   └── spectral.yaml            # Spectral linting ruleset
├── .github/workflows/
│   └── sync-and-enrich.yml # Main CI/CD workflow
├── reports/                # Generated reports (gitignored)
├── Makefile                # Build automation
├── .version                # Current semantic version
├── .etag                   # Last downloaded ETag
└── CHANGELOG.md            # Auto-generated changelog
```

## Read-Only Zones (CRITICAL)

**NEVER modify these directories/files**:

| Path | Reason |
|------|--------|
| `specs/original/` | Proprietary F5 specs, downloaded on schedule |
| `docs/specifications/api/` | Generated by pipeline, served by GitHub Pages |
| `specs/discovered/openapi.json` | Generated by discovery, tracked for CI/CD |
| `.version` | Managed by workflow, auto-incremented |
| `.etag` | Managed by download script |
| `CHANGELOG.md` | Auto-generated by workflow |

**Modification Pattern**: Change the pipeline scripts/config, not the outputs.

## Three Workflow Patterns

### 1. Discovery Workflow (VPN-Required, Local Only)

**Purpose**: Explore live F5 XC API to discover undocumented behavior and actual constraints.

**Prerequisites**:

- VPN connection to F5 XC API
- Environment variables: `F5XC_API_URL`, `F5XC_API_TOKEN`

**Commands**:

```bash
# Set credentials
export F5XC_API_URL="https://your-tenant.console.ves.volterra.io/api"
export F5XC_API_TOKEN="your-api-token"

# Run discovery (explores live API, generates specs/discovered/openapi.json)
make discover

# Push discovery data to GitHub for CI/CD consumption
make push-discovery

# Or combined: discover + push
make discover-and-push
```

**Outputs**:

- `specs/discovered/openapi.json` (25MB) - Full discovered API spec
- `specs/discovered/session.json` - Discovery session metadata
- `reports/discovery.log` - Discovery execution log

**Gotchas**:

- Discovery MUST run locally (VPN required)
- Never edit openapi.json manually - it's generated
- Always push discovery data for CI/CD to consume

### 2. Release Workflow (Automated via GitHub Actions)

**Purpose**: Sync specs from F5, run enrichment pipeline, create releases.

**Trigger**: Daily schedule, push to main, or manual dispatch.

**Flow**:

1. **Check Updates**: ETag comparison against F5 source
2. **Download**: Fetch new specs if changed
3. **Discovery Detection**: Check for committed discovery data
4. **Pipeline**: Enrich → Normalize → Merge → Lint
5. **Version Bump**: Auto-increment based on change type (see below)
6. **Release**: Create GitHub release with changelog
7. **Deploy**: Publish to GitHub Pages

**Change Detection** (PR #68):

The workflow monitors for changes in:

- `specs/original/` - Downloaded F5 source specifications
- `.etag` - Download cache file
- `scripts/` - Pipeline Python scripts
- `config/` - Configuration files (enrichment, normalization, discovery, spectral)
- `requirements.txt` - Python dependencies

**Version Bumping Logic**:

| Change Type | Files Changed | Version Bump | Example |
|-------------|---------------|--------------|---------|
| **Source specs** (new domains) | `specs/original/`, `.etag` + domain count ↑ | **Minor** | 1.0.15 → 1.1.0 |
| **Source specs** (no new domains) | `specs/original/`, `.etag` | **Patch** | 1.0.15 → 1.0.16 |
| **Pipeline changes** | `config/`, `scripts/`, `requirements.txt` | **Patch** | 1.0.15 → 1.0.16 |
| **Breaking changes** | Any + `[major]` or `BREAKING CHANGE` in commit | **Major** | 1.0.15 → 2.0.0 |

**Priority Order** (commit message overrides everything):

1. Explicit `[major]` or `BREAKING CHANGE` in commit message → Major bump
2. Source spec changes with new domains → Minor bump
3. Source spec changes without new domains → Patch bump
4. Pipeline/config/dependency changes → Patch bump
5. Unknown change types → Patch bump with warning

**Key Files**:

- `.github/workflows/sync-and-enrich.yml` - Main workflow
- `.version` - Current version (e.g., `1.0.14`)
- `CHANGELOG.md` - Auto-generated per release

### 3. Development Workflow (Local Testing)

**Purpose**: Local development, testing, and validation.

**Commands**:

```bash
# Full build (download → pipeline)
make build

# Quick rebuild (skip download, use existing specs)
make rebuild

# Individual steps
make download       # Download specs (ETag cached)
make pipeline       # Run enrichment pipeline
make lint           # Spectral OpenAPI linting
make validate       # Test against live API (needs credentials)

# Preview documentation
make serve          # http://localhost:8000

# Pre-commit hooks
make pre-commit-install  # Install git hooks
make pre-commit-run      # Run all hooks manually
```

**Pre-commit Hooks Run On Every Commit**:

1. F5 XC API Enrichment Pipeline (full rebuild)
2. Spectral linting (all 25 specs)
3. Security checks (gitleaks, detect-private-key)
4. Code quality (ruff, mypy, yamllint)
5. File hygiene (trailing whitespace, line endings)

## CLI Metadata Enrichment (Issue #152+)

**Purpose**: Enable AI assistants and CLI tools to generate working resource configurations.

**Features**:

Four OpenAPI extensions are added to schemas and specs:

1. **x-ves-minimum-configuration** (schema-level)
   - Description of minimum viable configuration
   - Required fields list
   - Example YAML configuration
   - Example xcsh CLI command
   - Applied to ALL resource schemas (5 configured + auto-generated for others)

2. **x-ves-cli-domain** (both schema and spec-level)
   - Domain classification (e.g., "virtual", "waf", "cdn")
   - At schema level: Resource classification
   - At spec level: Domain grouping metadata
   - Idempotent: Preserves existing values if present

3. **x-ves-required-for** (field-level)
   - Context-specific field requirements
   - Flags: minimum_config, create, update, read
   - Enables intelligent configuration generation

4. **x-ves-cli-aliases** (schema-level)
   - Alternative names for resources
   - Supports CLI command flexibility
   - Explicitly configured per resource

**Architecture**:

- **Stage 1 (Enrichment)**: MinimumConfigurationEnricher adds metadata to schemas
  - Configured resources use explicit config from `config/minimum_configs.yaml`
  - Unconfigured resources auto-generate from schema inspection
  - Uses DomainCategorizer for domain classification

- **Stage 2 (Merge)**: add_domain_metadata_to_spec() adds spec-level metadata
  - Spec info section gets x-ves-cli-domain from domain categorization
  - Spec index includes CLI domain metadata
  - Idempotent: Never overwrites existing values

**Configuration**:

- `config/minimum_configs.yaml`: Explicit configs for 5 priority resources
- `config/default_minimum_configs.yaml`: Default templates and patterns for auto-generation
- Pattern matching for resource type detection (e.g., "http_loadbalancerCreateRequest" → "http_loadbalancer")

**Testing**:

- 30 tests for explicit configurations (5 resources × parametrized patterns)
- 13 new tests for auto-generation and idempotency
- Total: 43 comprehensive tests with 82% code coverage

## Domain Description Enrichment (Issue #183)

**Purpose**: Apply DRY principle to domain descriptions with 3-tier descriptions for different use cases.

**Features**:

Three description tiers are generated and applied:

| Tier | Max Length | Use Case | Example |
|------|-----------|----------|---------|
| `short` | 60 chars | CLI columns, badges | "HTTP/HTTPS load balancing and traffic management" |
| `medium` | 150 chars | Tooltips, summaries | "Configure HTTP and HTTPS load balancers with origin pools, routing rules, and security integration." |
| `long` | 500 chars | Documentation, AI context | Full paragraph with capabilities and typical workflows |

**Architecture**:

```text
GENERATION (one-time per domain):
  scripts/generate_descriptions.py
    ├── Reads: specs/original/*.json (extract context)
    ├── Reads: scripts/utils/domain_metadata.py (use_cases)
    ├── Uses: Claude Code CLI (claude -p) for generation
    └── Writes: config/domain_descriptions.yaml

APPLICATION (every build):
  scripts/utils/description_enricher.py
    ├── Reads: config/domain_descriptions.yaml
    ├── Applies: info.description in domain specs (long tier)
    └── Integrated into: scripts/pipeline.py

  scripts/pipeline.py (create_spec_index)
    └── Applies: description_short, description_medium to index.json
```

**Configuration**:

- `config/domain_descriptions.yaml`: Central store for all domain descriptions

**Generating Descriptions**:

```bash
# Generate for a specific domain
python -m scripts.generate_descriptions --domain dns

# Generate for all domains without descriptions
python -m scripts.generate_descriptions --all

# Force regeneration even if descriptions exist
python -m scripts.generate_descriptions --domain virtual --force

# Dry run (show prompts without calling Claude)
python -m scripts.generate_descriptions --all --dry-run

# List domain description status
python -m scripts.generate_descriptions --list
```

**Key Classes**:

- `DescriptionEnricher`: Loads config and applies long description to `info.description`
- `DescriptionEnrichmentStats`: Tracks specs processed, descriptions applied/skipped

**Output Schema** (index.json):

```json
{
  "specifications": [
    {
      "domain": "virtual",
      "description": "Full long description...",
      "description_short": "HTTP/HTTPS load balancing...",
      "description_medium": "Configure HTTP and HTTPS load balancers..."
    }
  ]
}
```

**Testing**:

- 26 tests covering enricher basics, retrieval, spec enrichment, statistics
- Description length validation for all configured domains
- Run: `pytest tests/test_description_enricher.py -v`

## Key Gotchas

### 1. Pre-commit Pipeline Always Runs

**Issue**: Every commit triggers full pipeline (~50 seconds).
**Detection**: Watch for `F5 XC API Enrichment Pipeline...Passed` in commit output.
**Prevention**: This is intentional - ensures spec consistency.

### 2. Discovery Data Must Be Pushed Separately

**Issue**: `make discover` generates data locally; CI/CD cannot access VPN.
**Detection**: Check if `specs/discovered/openapi.json` is tracked in git.
**Prevention**: Always run `make push-discovery` after discovery.

### 3. Specs Are Gitignored But Pipeline Generates Them

**Issue**: `docs/specifications/api/` is gitignored but served by GitHub Pages.
**Detection**: Directory empty after clone, populated after `make pipeline`.
**Prevention**: Run `make build` or `make pipeline` before serving docs locally.

### 4. ETag Caching May Skip Downloads

**Issue**: `make download` may report "No changes" even when you expect updates.
**Detection**: Check `.etag` file modification date.
**Prevention**: Use `make download-force` to bypass ETag cache.

### 5. Version Is Managed By Workflow

**Issue**: Manually editing `.version` causes version conflicts.
**Detection**: Merge conflicts in `.version` file.
**Prevention**: Let workflow manage version; use commit messages for bump hints.

### 6. Large Files Need Pre-commit Exception

**Issue**: `check-added-large-files` blocks files over 1MB by default.
**Detection**: Pre-commit fails with "exceeds X KB" message.
**Prevention**: Add exclusion in `.pre-commit-config.yaml` for intentionally large files.

### 7. Config/Script Changes Trigger Patch Releases (PR #68)

**Issue**: Changes to enrichment rules, pipeline scripts, or dependencies now trigger patch releases automatically.
**Detection**: Pushing changes to `config/`, `scripts/`, or `requirements.txt` to main creates a new release.
**Behavior**:

- Config/script changes → patch bump (e.g., 1.0.15 → 1.0.16)
- Documentation and GitHub Pages automatically deployed with new release
- CHANGELOG.md auto-generated with change type information

**Impact**: This is intentional and correct - pipeline changes affect output quality and should be versioned.

### 8. Documentation-Only Changes Skip Pipeline

**Issue**: CLAUDE.md or README.md changes trigger workflow but skip expensive pipeline execution.
**Detection**: Workflow log shows "Documentation-only changes detected - skipping pipeline".
**Prevention**: This is intentional optimization - docs changes don't need full pipeline execution.
**Impact**: Saves ~50 seconds per docs-only commit.

**Behavior**:

- Pure documentation commits (CLAUDE.md, README.md, docs/**/*.md, LICENSE only) → Skip 50-second pipeline
- No release created for docs-only changes
- Mixed changes (docs + code) → Full pipeline runs normally

## Claude-Specific Instructions

### When User Says "Fix Specs"

1. **Clarify**: Which specs? Original (can't modify), enriched (modify pipeline), or discovered (regenerate)?
2. **Pattern**: Modify `config/enrichment.yaml` or `config/normalization.yaml`, not the output files.
3. **Validate**: Run `make pipeline && make lint` to verify changes.

### When User Says "Run Discovery"

1. **Verify**: Check VPN connection and environment variables.
2. **Execute**: `make discover` (takes several minutes, explores 300+ endpoints).
3. **Commit**: `make push-discovery` to make data available for CI/CD.
4. **Validate**: Check `specs/discovered/session.json` for success metrics.

### When User Says "Create Release"

1. **Never Manual**: Releases are automated via GitHub Actions.
2. **Trigger**: Push to main or manual workflow dispatch.
   - Source spec changes → auto-release with patch/minor bump
   - Config/script changes → auto-release with patch bump (PR #68)
   - No relevant changes → workflow skips release
3. **Monitor**: Watch workflow run for completion.
4. **Verify**: Check GitHub Releases page for new release (v1.0.X).
5. **Documentation**: GitHub Pages automatically deployed with release.

### When User Says "Update Dependencies"

1. **Python**: Modify `requirements.txt`, run `make install`.
2. **Pre-commit**: Run `pre-commit autoupdate` for hook versions.
3. **Node**: Install via npm for Spectral CLI.
4. **Test**: Run `make pre-commit-run` to validate all hooks.

### When User Says "Debug Pipeline"

1. **Individual Steps**: Run `make enrich`, `make normalize`, `make merge` separately.
2. **Reports**: Check `reports/pipeline-report.json` for detailed metrics.
3. **Lint Issues**: Run `make lint` and check `reports/lint-report.json`.
4. **Verbose**: Add `--verbose` to pipeline commands for debug output.

## Documentation Generators (v1.0.52+)

**Major Refactoring**: All documentation generators now inherit from a shared `BaseReporter` class, use centralized `PathConfig` for path management, and integrate server variables into all markdown output.

### Shared Reporting Infrastructure

**Files Created**:

- `scripts/utils/report_base.py` - Abstract base class for all reporters with unified markdown/JSON generation
- `scripts/utils/path_config.py` - Singleton for centralized path management (respects `config/paths.yaml`)
- `scripts/utils/server_variables_markdown.py` - Server variables rendering utilities for consistent documentation
- `scripts/utils/lint_reporter.py` - Extracted from lint.py, now generates both JSON and markdown
- `scripts/utils/validation_reporter.py` - Extracted from validate.py, now generates both JSON and markdown

**Benefits**:

- **Code Deduplication**: Eliminated 40-50% duplication across generators
- **Consistent Paths**: All generators use `PathConfig`, no hardcoded paths
- **Server Variables**: All markdown reports include multi-environment server variable documentation
- **Dual Format**: Linting and validation now generate markdown reports in addition to JSON

### Four Documentation Generators

All generators now:

1. Use `PathConfig` for output path management
2. Generate both Markdown (human-readable) and JSON (machine-parseable) reports
3. Include server variables section in markdown output
4. Follow consistent naming and structure

#### 1. Discovery Report Generator (`scripts/discovery/report_generator.py`)

**Outputs**:

- `reports/discovery-report.md` - Human-readable discovery summary with server variables
- `specs/discovered/openapi.json` - Full discovered API specification
- `specs/discovered/session.json` - Discovery session metadata
- `specs/discovered/diffs/summary.json` - Schema differences found

**Key Sections**:

- Endpoint exploration summary
- Rate limiting statistics
- Schema differences (tighter constraints, new constraints)
- Notable discoveries
- Server variable configuration section

#### 2. Constraint Analysis Generator (`scripts/utils/constraint_analyzer.py`)

**Outputs**:

- `reports/constraint-analysis.md` - Tighter/new constraints with recommendations
- `reports/constraint-analysis.json` - Machine-parseable constraint analysis

**Key Sections**:

- Tighter constraints discovered in live API
- New constraints found but undocumented
- Undocumented fields in API responses
- Server variable constraints section

#### 3. Linting Report Generator (`scripts/lint.py` with `scripts/utils/lint_reporter.py`)

**Outputs**:

- `reports/lint-report.md` - OpenAPI specification validation results
- `reports/lint-report.json` - JSON format for CI/CD integration

**Key Sections**:

- Summary table (files processed, passed, failed, errors, warnings)
- Server configuration section (required for lint validation workflows)
- Files with most issues
- Errors, warnings, and info sections

#### 4. Validation Report Generator (`scripts/validate.py` with `scripts/utils/validation_reporter.py`)

**Outputs**:

- `reports/validation-report.md` - Live API endpoint validation results
- `reports/validation-report.json` - JSON format for CI/CD integration

**Key Sections**:

- Executive summary
- Validation metrics (availability %, schema match %)
- Server configuration validation section
- Specification-by-specification results
- Endpoint coverage analysis
- Schema discrepancies

### Server Variables in Documentation

All markdown reports now include a **Server Configuration** section documenting:

- **URL Template**: How variables are combined to form the API URL
- **Variable Definitions**: Each variable with default, description, environment variable name, and examples
- **GitHub Branch Mapping**: How Git branches map to namespaces in CI/CD pipelines

This enables users to:

- Understand multi-environment, multi-tenant deployments
- Configure Swagger UI with correct server variables
- Set up CI/CD pipelines with proper environment/tenant/region targeting

## Environment Variables

| Variable | Purpose | Required For |
|----------|---------|--------------|
| `F5XC_TENANT` | Tenant identifier for OpenAPI server variables | Pipeline defaults, Swagger UI defaults |
| `F5XC_CONSOLE_URL` | Console URL base for OpenAPI server variables | Pipeline defaults, Swagger UI defaults |
| `F5XC_DEFAULT_NAMESPACE` | Default namespace for OpenAPI server variables | Pipeline defaults, Swagger UI defaults |
| `F5XC_ENVIRONMENT` | Environment designation for OpenAPI server variables | Pipeline defaults, Swagger UI defaults |
| `F5XC_REGION` | Geographic region for OpenAPI server variables | Pipeline defaults, Swagger UI defaults |
| `F5XC_DOMAIN_PREFIX` | Domain naming prefix for OpenAPI server variables | Pipeline defaults, Swagger UI defaults |
| `F5XC_API_URL` | F5 XC API endpoint URL (legacy, for discovery) | Discovery, Validation |
| `F5XC_API_TOKEN` | API authentication token | Discovery, Validation |
| `GITHUB_TOKEN` | GitHub API access (in workflows) | Releases, Issues |
| `DISCOVERY_ENRICHMENT_ENABLED` | Enable discovery enrichment | Pipeline (auto-set) |

## Multi-Environment Server Variables

The OpenAPI specifications support multi-environment, multi-tenant, and multi-region deployments through 6 server variables. This enables selecting different API endpoints, environments, and deployment regions directly in Swagger UI without manual URL construction.

### Server Variable Configuration

**Active Variables** (in Swagger UI "Server variables" section):

**URL Components** (part of computed URL):

- `tenant`: F5 Distributed Cloud tenant identifier (default: `example-corp`)
- `console_url`: Console URL base - encodes environment and hosting (default: `console.ves.volterra.io`)
- `namespace`: Kubernetes-style namespace for environment separation (default: `default`)

**Configuration Variables** (available for API clients and tooling):

- `environment`: Explicit environment designation (default: `production`) - Options: production, staging, development
- `region`: Geographic region for multi-region deployments (default: `us-east-1`) - Examples: us-east-1, eu-west-1, ap-northeast-1
- `domain_prefix`: Industry-standard naming conventions (default: `api`) - Examples: api, api-edge, internal

**Server URL Template**:

```text
https://{tenant}.{console_url}/api/v1/{domain_prefix}/{environment}/{region}/namespaces/{namespace}
```

### Tenant Variable

The `tenant` variable specifies your F5 Distributed Cloud tenant identifier - the corporate account you're working with.

**Default Behavior**:

- Reads from `F5XC_TENANT` environment variable if available
- Falls back to: `example-corp`

**Examples**:

- `example-corp`: Example corporation tenant
- `acme-inc`: ACME Inc. tenant
- `my-company`: Your company tenant

**Setting Tenant**:

```bash
# Option 1: Environment variable
export F5XC_TENANT="your-company"
# Swagger UI will default to this tenant

# Option 2: Override in Swagger UI
# Select your tenant from the "Server variables" section
```

**Pattern**: Lowercase alphanumeric with hyphens (RFC 1123 compliant)

### Console URL Variable

The `console_url` variable specifies the console URL base, encoding both the environment and hosting region.

**Default Behavior**:

- Reads from `F5XC_CONSOLE_URL` environment variable if available
- Falls back to: `console.ves.volterra.io`

**Examples**:

| Environment | Console URL | Use Case |
|-------------|------------|----------|
| Production | `console.ves.volterra.io` | Production API calls |
| Staging | `staging.volterra.us` | Staging/Testing configurations |
| Custom | `custom-api.f5xc.io` | Custom F5 XC deployments |

**Generated URLs by Example**:

- Tenant: `example-corp`, Console URL: `console.ves.volterra.io`, Namespace: `production`
  → `https://example-corp.console.ves.volterra.io/api/v1/namespaces/production`

- Tenant: `example-corp`, Console URL: `staging.volterra.us`, Namespace: `staging`
  → `https://example-corp.staging.volterra.us/api/v1/namespaces/staging`

**Setting Console URL**:

```bash
# Option 1: Environment variable
export F5XC_CONSOLE_URL="staging.volterra.us"
# Swagger UI will default to this console URL

# Option 2: Override in Swagger UI
# Select your console URL from the "Server variables" section
```

### Environment Variable

The `environment` variable specifies the environment designation (production, staging, development) and is available for API clients and tooling to use.

**Default Behavior**:

- Reads from `F5XC_ENVIRONMENT` environment variable if available
- Falls back to: `production`

**Options**: `production`, `staging`, `development`

**Setting Environment**:

```bash
export F5XC_ENVIRONMENT="staging"
```

### Region Variable

The `region` variable specifies the geographic region for multi-region deployments and is available for clients to use for region-aware routing.

**Default Behavior**:

- Reads from `F5XC_REGION` environment variable if available
- Falls back to: `us-east-1`

**Examples**: `us-east-1`, `us-west-1`, `eu-west-1`, `eu-central-1`, `ap-northeast-1`

**Setting Region**:

```bash
export F5XC_REGION="eu-west-1"
```

### Domain Prefix Variable

The `domain_prefix` variable specifies naming conventions and is available for advanced API client configurations.

**Default Behavior**:

- Reads from `F5XC_DOMAIN_PREFIX` environment variable if available
- Falls back to: `api`

**Examples**: `api`, `api-edge`, `internal`

**Setting Domain Prefix**:

```bash
export F5XC_DOMAIN_PREFIX="api-edge"
```

### Namespace Variable with Environment Support

The `namespace` variable now supports the `F5XC_DEFAULT_NAMESPACE` environment variable for consistent environment selection.

**Default Behavior**:

- Reads from `F5XC_DEFAULT_NAMESPACE` environment variable if available
- Falls back to: `default`

**Setting Namespace Defaults**:

```bash
# Option 1: Environment variable
export F5XC_DEFAULT_NAMESPACE="production"
# All generated specs will default to production namespace

# Option 2: Override in API client/tool
# Use the Swagger UI or your API client to select a different namespace value

# Option 3: GitHub branch aware (with CI/CD integration)
# Automatically maps branches to namespaces:
# - main → main
# - staging → staging
# - feature/issue-123 → feature-123
```

**Environment Examples**:

| Scenario | Environment Setup | Result |
|----------|-------------------|--------|
| Local development | `export F5XC_DEFAULT_NAMESPACE="default"` | All requests to default namespace |
| Staging environment | `export F5XC_DEFAULT_NAMESPACE="staging"` | All requests to staging namespace |
| Production deployment | `export F5XC_DEFAULT_NAMESPACE="production"` | All requests to production namespace |

### GitHub-Based Deployment Strategy

Map GitHub branches to namespaces automatically for multi-environment CI/CD:

- `main` branch → production namespace "main"
- `feature/issue-{num}` → feature namespace "feature-{num}" (development)
- `bugfix/issue-{num}` → bugfix namespace "bugfix-{num}" (development)
- `staging` branch → staging namespace "staging"
- Other branches → default namespace "default"

This enables:

- Separate production deployments (main namespace) from feature/bugfix work
- Independent namespace isolation prevents naming conflicts
- Zero-downtime deployments with namespace-based environment selection
- Automatic deployment targeting based on GitHub branch

### Using in Swagger UI

1. Open [Swagger UI documentation](https://robinmordasiewicz.github.io/f5xc-api-enriched/swagger-ui/)
2. Look for "Server variables" section at the top
3. Select your deployment configuration:
   - **Tenant**: Your F5 XC tenant identifier (e.g., `example-corp`, `acme-inc`)
   - **Console URL**: Console base URL (e.g., `console.ves.volterra.io` for production, `staging.volterra.us` for staging)
   - **Namespace**: Environment namespace (e.g., `main` for production, `staging`, `default`)
   - **Environment**: Environment designation (e.g., `production`, `staging`, `development`)
   - **Region**: Geographic region (e.g., `us-east-1`, `eu-west-1`)
   - **Domain Prefix**: Domain naming convention (e.g., `api`, `api-edge`)
4. The computed URL updates automatically to reflect your selection
5. All API calls use the selected variables

**Example Configuration in Swagger UI**:

```yaml
tenant: my-company
console_url: console.ves.volterra.io
namespace: production
environment: production
region: us-east-1
domain_prefix: api

# Computed URL: https://my-company.console.ves.volterra.io/api/v1/namespaces/production
```

### Configuration Framework

The server variable framework supports comprehensive multi-environment deployments. Current configuration file: `config/server_variables.yaml`

**All 6 Variables Now Active**:

Version 2.0.0 of the configuration includes all 6 variables:

- **URL Components**: `tenant`, `console_url`, `namespace` (used in computed URL)
- **Configuration Variables**: `environment`, `region`, `domain_prefix` (available for API clients and tooling)

Each variable:

- Has environment variable mapping (F5XC_* pattern)
- Supports enumerated values where applicable
- Includes sensible defaults
- Is documented with examples and use cases

## Common Operations

### Add New Enrichment Rule

```yaml
# config/enrichment.yaml
acronyms:
  NEW_TERM: "New Term Expansion"
```

### Add New Normalization Rule

```yaml
# config/normalization.yaml
type_fixes:
  - pattern: "oldType"
    replacement: "newType"
```

### Skip Pre-commit Hooks (Emergency Only)

```bash
git commit --no-verify -m "emergency: fix critical issue"
```

### Force Full Rebuild

```bash
make clean && make build
```

### Check Discovery Data Age

```bash
jq '.started_at' specs/discovered/session.json
```

### Test Workflow Skip Logic

```bash
# Test docs-only early exit (should skip pipeline in ~5s)
echo "\n## Test" >> CLAUDE.md
git add CLAUDE.md
git commit -m "docs: test early exit"
git push

# Test workflow file detection (should create patch release)
# Edit .github/workflows/sync-and-enrich.yml (add comment), then:
git add .github/workflows/sync-and-enrich.yml
git commit -m "ci: test workflow detection"
git push

# Test config file detection (should create patch release)
echo "  # test: test" >> config/enrichment.yaml
git add config/enrichment.yaml
git commit -m "config: test config detection"
git push
```

## Anti-Patterns to Avoid

1. **Never edit `specs/original/`** - These are downloaded from F5.
2. **Never edit `docs/specifications/api/`** - These are generated by pipeline.
3. **Never manually edit `.version`** - Workflow manages versioning.
4. **Never commit to main directly** - Use feature branches.
5. **Never skip pre-commit hooks regularly** - They ensure consistency.
6. **Never hardcode credentials** - Use environment variables.
7. **Never run discovery without VPN** - API is not publicly accessible.

## Testing Changes

Before committing any changes:

```bash
# Run full pipeline
make pipeline

# Lint all specs
make lint

# Run all pre-commit hooks
make pre-commit-run

# If discovery-related, also run:
make discover-dry-run  # List endpoints without making requests
```
