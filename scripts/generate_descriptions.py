#!/usr/bin/env python3
"""Generate enriched domain descriptions using Claude Code CLI.

Uses `claude -p` in headless mode to generate 3-tier descriptions
(short, medium, long) for each API domain based on source spec context.

Usage:
    # Generate for specific domain
    python scripts/generate_descriptions.py --domain virtual

    # Generate for all domains without descriptions
    python scripts/generate_descriptions.py --all

    # Force regeneration even if descriptions exist
    python scripts/generate_descriptions.py --domain virtual --force

    # Dry run (show prompts without calling Claude)
    python scripts/generate_descriptions.py --all --dry-run
"""

import argparse
import hashlib
import json
import re
import subprocess
import sys
from dataclasses import dataclass, field
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

import yaml

from scripts.utils.domain_categorizer import DomainCategorizer
from scripts.utils.domain_metadata import DOMAIN_METADATA

# =============================================================================
# STRUCTURED VIOLATION SYSTEM
# Provides precise, actionable feedback for self-refine loops
# =============================================================================


@dataclass
class Violation:
    """Structured violation data for precise feedback in self-refine loops.

    Instead of string parsing, this provides:
    - Exact location of the problem
    - Specific fix guidance
    - Concrete examples of correct alternatives
    """

    layer: str  # "banned_patterns", "self_referential", "quality", "circular", "cross_tier"
    tier: str  # "short", "medium", "long", or "cross_tier"
    code: str  # "DOMAIN_NAME", "WORD_REPETITION", "STYLE", etc.
    message: str  # Human-readable description
    location: str  # Exact text that triggered violation
    suggestion: str  # Specific fix recommendation
    examples: list[str] = field(default_factory=list)  # Good alternatives

    def __str__(self) -> str:
        """Return string representation for backward compatibility."""
        return f"{self.tier}: {self.message}"

    def to_feedback(self) -> str:
        """Generate specific, actionable feedback for the LLM."""
        parts = [
            f"### Issue: {self.code} in {self.tier.upper()}",
            f"**Problem**: {self.message}",
            f'**Found**: "{self.location}"',
            f"**Fix**: {self.suggestion}",
        ]
        if self.examples:
            parts.append(f'**Example**: "{self.examples[0]}"')
        return "\n".join(parts)


# Domain-specific synonyms for avoiding self-reference
# Maps domain names to functional alternatives
DOMAIN_SYNONYMS: dict[str, list[str]] = {
    # Infrastructure domains
    "observability": ["monitoring infrastructure", "telemetry systems", "metrics pipelines"],
    "sites": ["edge locations", "deployment points", "regional nodes"],
    "network": ["connectivity", "traffic routing", "data paths"],
    "cloud_infrastructure": ["compute resources", "deployment targets", "hosting platforms"],
    # Security domains
    "authentication": ["identity verification", "access control", "credential management"],
    "waf": ["request filtering", "attack prevention", "traffic inspection"],
    "ddos": ["flood protection", "traffic scrubbing", "rate enforcement"],
    "bot_and_threat_defense": ["automated threat blocking", "malicious traffic filtering"],
    "network_security": ["perimeter controls", "traffic policies", "access rules"],
    "data_and_privacy_security": ["sensitive data handling", "privacy controls"],
    # Delivery domains
    "cdn": ["content delivery", "edge caching", "distribution networks"],
    "dns": ["name resolution", "record management", "zone configuration"],
    "virtual": ["load distribution", "traffic management", "request routing"],
    # Management domains
    "certificates": ["TLS credentials", "SSL management", "PKI operations"],
    "users": ["account management", "role assignments", "permission controls"],
    "tenant_and_identity": ["organization settings", "identity providers"],
    "billing_and_usage": ["consumption tracking", "cost management"],
    # Operations domains
    "telemetry_and_insights": ["metrics collection", "performance analysis"],
    "statistics": ["usage metrics", "performance data", "trend analysis"],
    "support": ["help resources", "troubleshooting tools"],
    # Other domains
    "api": ["interface definitions", "schema management"],
    "container_services": ["workload orchestration", "pod management"],
    "managed_kubernetes": ["cluster operations", "node management"],
    "service_mesh": ["microservice routing", "sidecar configuration"],
    "rate_limiting": ["request throttling", "quota enforcement"],
    "marketplace": ["service catalog", "add-on management"],
    "ce_management": ["customer edge control", "site operations"],
    "vpm_and_node_management": ["node lifecycle", "edge provisioning"],
    "generative_ai": ["model integration", "inference routing"],
    "blindfold": ["secret encryption", "key management"],
    "bigip": ["legacy integration", "device management"],
    "shape": ["client integrity", "fraud prevention"],
    "threat_campaign": ["attack patterns", "threat intelligence"],
    "secops_and_incident_response": ["security automation", "alert handling"],
    "object_storage": ["blob management", "file distribution"],
    "nginx_one": ["proxy configuration", "gateway management"],
    "data_intelligence": ["traffic analysis", "behavioral insights"],
    "openapi": ["schema definitions", "interface contracts"],
    "admin_console_and_ui": ["dashboard access", "portal configuration"],
}


# Successful description patterns by domain category
# These examples demonstrate NOUN-FIRST, DRY-compliant descriptions
# CRITICAL: Do NOT start with CRUD verbs (Configure, Manage, Deploy, etc.)
# because they're implied in API context and waste character budget
SUCCESSFUL_PATTERNS: dict[str, dict[str, str]] = {
    "infrastructure": {
        "short": "Edge nodes, regional clusters, and cloud sites.",
        "medium": "Multi-cloud deployments with automated provisioning. Health monitoring and failover policies.",
        "long": (
            "Geographic distribution across AWS, Azure, GCP with node lifecycle management. "
            "VPC peering, transit gateways, and capacity metrics for enterprise scale."
        ),
    },
    "security": {
        "short": "Firewall rules, access controls, and threat detection.",
        "medium": "Security policies with WAF rules and rate limits. Anomaly detection and blocking.",
        "long": (
            "Perimeter defense with signature-based detection and automated blocking. "
            "SSL inspection, DDoS mitigation, and compliance reporting for enterprise security."
        ),
    },
    "delivery": {
        "short": "Origin pools, load balancing, and traffic routing.",
        "medium": "Health-checked origin servers with routing policies. Session persistence and failover.",
        "long": (
            "Traffic distribution across regions with weighted routing. SSL termination, "
            "caching policies, and latency monitoring for optimal performance."
        ),
    },
    "management": {
        "short": "Organization settings, roles, and permissions.",
        "medium": "Role-based access with identity provider integration. Audit logging and compliance.",
        "long": (
            "Organizational hierarchy with delegated administration. SSO integration, "
            "audit trails, and compliance controls for enterprise governance."
        ),
    },
    "operations": {
        "short": "Metrics, dashboards, alerts, and log aggregation.",
        "medium": "Custom monitoring dashboards with alerting rules. Performance analytics.",
        "long": (
            "Traffic pattern analysis with centralized logging. Automated remediation, "
            "SLA tracking, and capacity planning for operational excellence."
        ),
    },
}

# Map domain categories to pattern categories
CATEGORY_TO_PATTERN: dict[str, str] = {
    "Infrastructure": "infrastructure",
    "Infrastructure Management": "infrastructure",
    "Security": "security",
    "Delivery": "delivery",
    "Management": "management",
    "Operations": "operations",
    "Other": "infrastructure",  # Default fallback
}


# Constants
CONFIG_PATH = Path("config/domain_descriptions.yaml")
ORIGINAL_SPECS_PATH = Path("specs/original")
DOMAIN_PATTERNS_PATH = Path("config/domain_patterns.yaml")

# Description tier constraints
MAX_SHORT = 60
MAX_MEDIUM = 150
MAX_LONG = 500

# Valid tier names for filtering (excludes metadata like source_patterns_hash)
VALID_TIERS = frozenset({"short", "medium", "long"})

# JSON Schema for Claude Code structured output
DESCRIPTION_SCHEMA = {
    "type": "object",
    "properties": {
        "short": {"type": "string"},
        "medium": {"type": "string"},
        "long": {"type": "string"},
    },
    "required": ["short", "medium", "long"],
}


def load_config() -> dict[str, Any]:
    """Load existing domain descriptions config."""
    if not CONFIG_PATH.exists():
        return {"version": "1.0.0", "domains": {}}

    with CONFIG_PATH.open() as f:
        return yaml.safe_load(f) or {"version": "1.0.0", "domains": {}}


def save_config(config: dict[str, Any]) -> None:
    """Save domain descriptions config."""
    config["generated_at"] = datetime.now(tz=timezone.utc).isoformat()

    with CONFIG_PATH.open("w") as f:
        yaml.dump(config, f, default_flow_style=False, sort_keys=False, allow_unicode=True)


def get_domain_source_specs(domain: str) -> list[Path]:
    """Get source spec files that belong to a domain."""
    categorizer = DomainCategorizer()
    return [
        spec_file
        for spec_file in ORIGINAL_SPECS_PATH.glob("*.json")
        if categorizer.categorize(spec_file.name) == domain
    ]


def _load_spec_safely(spec_path: Path) -> dict[str, Any] | None:
    """Load a spec file, returning None if it fails."""
    try:
        with spec_path.open() as f:
            return json.load(f)
    except (json.JSONDecodeError, OSError):
        return None


def compute_source_patterns_hash(domain: str) -> str:
    """Compute a stable hash of source spec patterns for change detection.

    Creates a SHA256 hash based on:
    - Sorted list of source spec filenames
    - Sorted list of all paths in those specs
    - Sorted list of all schema names in those specs

    Args:
        domain: Domain name to compute hash for

    Returns:
        SHA256 hash prefixed with 'sha256:'
    """
    source_specs = get_domain_source_specs(domain)

    # Collect patterns from all specs
    patterns = {
        "files": sorted([spec.name for spec in source_specs]),
        "paths": [],
        "schemas": [],
    }

    for spec_path in source_specs:
        spec = _load_spec_safely(spec_path)
        if spec:
            patterns["paths"].extend(spec.get("paths", {}).keys())
            patterns["schemas"].extend(
                spec.get("components", {}).get("schemas", {}).keys(),
            )

    # Sort and deduplicate
    patterns["paths"] = sorted(set(patterns["paths"]))
    patterns["schemas"] = sorted(set(patterns["schemas"]))

    # Create stable JSON representation and hash it
    content = json.dumps(patterns, sort_keys=True)
    hash_value = hashlib.sha256(content.encode()).hexdigest()

    return f"sha256:{hash_value}"


def extract_spec_context(spec_path: Path) -> dict[str, Any]:
    """Extract context from a source spec for prompt generation."""
    with spec_path.open() as f:
        spec = json.load(f)

    return {
        "title": spec.get("info", {}).get("title", ""),
        "description": spec.get("info", {}).get("description", ""),
        "paths": list(spec.get("paths", {}).keys())[:20],  # First 20 paths
        "schemas": list(spec.get("components", {}).get("schemas", {}).keys())[:30],
        "path_count": len(spec.get("paths", {})),
        "schema_count": len(spec.get("components", {}).get("schemas", {})),
    }


def get_domain_context(domain: str) -> dict[str, Any]:
    """Gather all context for a domain."""
    # Get metadata from domain_metadata.py
    metadata = DOMAIN_METADATA.get(domain, {})

    # Get source specs and extract context
    source_specs = get_domain_source_specs(domain)
    spec_contexts = [extract_spec_context(spec) for spec in source_specs[:5]]  # First 5 specs

    # Aggregate paths and schemas
    all_paths = []
    all_schemas = []
    for ctx in spec_contexts:
        all_paths.extend(ctx.get("paths", []))
        all_schemas.extend(ctx.get("schemas", []))

    # Deduplicate and limit
    unique_paths = list(dict.fromkeys(all_paths))[:30]
    unique_schemas = list(dict.fromkeys(all_schemas))[:40]

    return {
        "domain": domain,
        "domain_title": domain.replace("_", " ").title(),
        "use_cases": metadata.get("use_cases", []),
        "related_domains": metadata.get("related_domains", []),
        "domain_category": metadata.get("domain_category", "Other"),
        "paths": unique_paths,
        "schemas": unique_schemas,
        "spec_count": len(source_specs),
    }


def build_prompt(domain: str, context: dict[str, Any]) -> str:
    """Build the prompt for Claude to generate descriptions.

    Uses research-based technical writing guidelines (Google, Microsoft, Apple)
    for consistent, DRY-compliant descriptions that fit character limits naturally.
    """
    use_cases_str = "\n".join(f"  - {uc}" for uc in context.get("use_cases", []))
    paths_str = "\n".join(f"  - {p}" for p in context.get("paths", [])[:15])
    schemas_str = ", ".join(context.get("schemas", [])[:20])

    # Domain name variants to ban (the domain and common transforms)
    domain_variants = domain.replace("_", " ")

    # Get successful pattern based on domain category
    category = context.get("domain_category", "Other")
    pattern_key = CATEGORY_TO_PATTERN.get(category, "infrastructure")
    pattern = SUCCESSFUL_PATTERNS.get(pattern_key, SUCCESSFUL_PATTERNS["infrastructure"])

    # Build successful patterns section with domain-specific synonyms
    domain_synonyms = DOMAIN_SYNONYMS.get(domain, ["infrastructure", "systems", "services"])
    synonyms_hint = f"(NEVER use '{domain_variants}' - use: {', '.join(domain_synonyms[:3])})"

    successful_patterns_section = f"""
SHORT ({len(pattern["short"])} chars): "{pattern["short"]}"
MEDIUM ({len(pattern["medium"])} chars): "{pattern["medium"]}"
LONG ({len(pattern["long"])} chars): "{pattern["long"]}"

{synonyms_hint}
"""

    prompt = f"""Generate 3-tier descriptions for the "{context["domain_title"]}" domain.

CONTEXT:
Domain: {domain}
Category: {context.get("domain_category", "Other")}
Related: {", ".join(context.get("related_domains", []))}
Specs: {context.get("spec_count", 0)} source specifications

Use cases:
{use_cases_str or "  - (none specified)"}

Sample paths:
{paths_str or "  - (none)"}

Schemas: {schemas_str or "(none)"}

═══════════════════════════════════════════════════════════════════════════════
STRICT RULES - Violations cause INSTANT REJECTION:

1. BANNED TERMS BY CATEGORY:

   REDUNDANT (these ARE API specs - never state the obvious):
   ✗ "API", "REST API", "endpoint", "specifications", "spec"

   BRAND NAMES (never reference products):
   ✗ "F5", "F5 XC", "XC", "Distributed Cloud", "Volterra"

   FILLER WORDS (use simpler alternatives):
   ✗ "utilize" → use "use"
   ✗ "leverage" → use "use"
   ✗ "facilitate" → use "enable"
   ✗ "in order to" → use "to"

   VAGUE DESCRIPTORS (be specific or omit):
   ✗ "various", "multiple", "several", "etc.", "and more", "diverse"

   MARKETING HYPE (state facts, not opinions):
   ✗ "seamless", "robust", "powerful", "cutting-edge", "innovative"
   ✗ "enterprise-grade", "world-class", "best-in-class", "superior"

   SELF-REFERENCE (domain name in description is redundant):
   ✗ "{domain_variants}" (the domain name itself)

2. ACTIVE VOICE REQUIRED (passive voice = instant rejection):
   ✗ "Data is returned" → ✓ "Returns data"
   ✗ "Connections are managed" → ✓ "Manages connections"
   ✗ "Security is handled" → ✓ "Handles security"

3. NOUN-FIRST, VALUE-ADD DESCRIPTIONS (CRITICAL - DRY COMPLIANCE):
   Since this is a CRUD API, users already know they can configure/manage/deploy.
   DO NOT waste characters on implied operations. Instead, describe:
   - WHAT resources/concepts exist in this domain
   - WHAT technical capabilities are available
   - WHAT specific features differentiate this domain

   ✗ BANNED STARTERS (redundant in API context):
     "Configure...", "Manage...", "Create...", "Deploy...", "Monitor...",
     "Access...", "Define...", "Set up...", "Enable...", "Control...", "Handle..."

   ✗ ALSO BANNED: "This", "The", "A", "An", "Provides", "Enables", "Offers"

   ✓ GOOD PATTERNS (noun-first, information-dense):
     "HTTP, TCP, UDP load balancing with origin pool health checks."
     "Authoritative zones, record types, and DNS-based failover."
     "Request inspection, attack signatures, and bot mitigation."

   The first word should be a NOUN or NOUN-PHRASE describing domain concepts.

4. PROGRESSIVE INFORMATION (no repetition across tiers):
   - SHORT: Primary capability only (the core "what")
   - MEDIUM: Add secondary features + benefit (the "what else" + "why")
   - LONG: Add mechanics, options, usage context (the "how" + "when")

   CRITICAL: If a concept appears in SHORT, it MUST NOT appear in MEDIUM or LONG.
   Each tier reveals NEW information only.

═══════════════════════════════════════════════════════════════════════════════
COMPRESSION TECHNIQUES - Apply these to stay under limits:

• Remove articles: "the load balancers" → "load balancers"
• Remove qualifiers: "global distribution" → "distribution"
• Shorten phrases: "for domain resolution" → (remove entirely)
• Remove redundant words: "authoritative name services" → "name services"

NEGATIVE EXAMPLES (from actual failures - DO NOT repeat these patterns):
❌ "Configure content delivery and caching policies for global distribution" (71 chars)
   → Noun-first rewrite: "Content delivery and edge caching." (35 chars) ✓

❌ "Manage zones, records, and load balancing for domain resolution" (63 chars)
   → Noun-first rewrite: "DNS zones, record types, and load balancing." (45 chars) ✓

═══════════════════════════════════════════════════════════════════════════════
CHARACTER LIMITS - WRITE TO FIT, NEVER TRUNCATE:

⚠️ CRITICAL: Write descriptions that NATURALLY fit within limits.
   NEVER write long text and truncate it. No "..." endings. No partial sentences.
   If your draft is too long, REWRITE it shorter - do not cut it off.

SHORT (TARGET: 35-50 chars, HARD MAX: {MAX_SHORT}):
  • Format: [Noun/Concept phrase ending with period]
  • Start with WHAT exists, not what users DO
  • Remove ALL unnecessary words
  • If over 50 chars, REMOVE WORDS (don't truncate!)
  • Examples:
    ✓ "HTTP load balancers and traffic distribution." (46 chars)
    ✓ "WAF rules, rate limits, and bot protection." (44 chars)
    ✓ "Edge nodes, clusters, and cloud sites." (39 chars)
    ✗ TOO LONG (71 chars): "Configure content delivery and caching..."

MEDIUM (TARGET: 100-130 chars, HARD MAX: {MAX_MEDIUM}):
  • Two short noun-first sentences
  • If over 130 chars, REWRITE with fewer words (don't truncate!)
  • Example (82 chars): "Routing rules, health checks, and failover. Traffic distribution controls."
  • AVOID long phrases like "with support for BIND and AXFR transfer protocols"

LONG (TARGET: 350-450 chars, HARD MAX: {MAX_LONG}):
  • 3-4 sentences, stay under 450 to be safe
  • If over 450 chars, SIMPLIFY sentences (don't truncate!)
  • Remove verbose qualifiers ("authoritative", "global", "comprehensive")

═══════════════════════════════════════════════════════════════════════════════
SUCCESSFUL EXAMPLE - Follow this structure and style:
{successful_patterns_section}
═══════════════════════════════════════════════════════════════════════════════
OUTPUT FORMAT:

Respond with JSON only: {{"short": "...", "medium": "...", "long": "..."}}

BEFORE RESPONDING - MANDATORY VERIFICATION CHECKLIST:

⚠️ NEVER TRUNCATE - If any tier exceeds its target, REWRITE IT SHORTER.
   Truncated text with "..." is REJECTED. Incomplete sentences are REJECTED.

CHARACTER LIMITS:
□ SHORT ≤50 chars (if over, REWRITE - never cut off!)
□ MEDIUM ≤130 chars (if over, REWRITE - never cut off!)
□ LONG ≤450 chars (if over, REWRITE - never cut off!)

BANNED PATTERNS (instant rejection):
□ No "API", "endpoint", "specifications" (redundant)
□ No "F5", "XC", "Volterra" (brand names)
□ No "utilize", "leverage", "facilitate" (filler words)
□ No "various", "multiple", "etc." (vague descriptors)
□ No "seamless", "robust", "powerful" (marketing hype)
□ No passive voice ("is returned", "are handled")

STYLE REQUIREMENTS (DRY-COMPLIANT):
□ Each tier starts with NOUN/CONCEPT (not action verbs)
□ NO CRUD verbs: Configure, Manage, Deploy, Create, Monitor, Access
□ No tier starts with "This", "The", "A", "Provides", "Enables"
□ Active voice throughout (no "is/are + past participle")
□ No ellipsis "..." or incomplete sentences

COMPLETE THOUGHT REQUIREMENT (CRITICAL - instant rejection for violations):
□ Every tier MUST end with a period (.) - no exceptions
□ NEVER end a sentence with: and, or, with, for, to, the, a, an
□ If your draft exceeds the limit, REWRITE it shorter as a complete thought
□ Examples:
  ✓ "Load balancers and health checks." (complete thought)
  ✗ "Load balancers and" (cut-off mid-phrase)
  ✗ "Load balancers with" (incomplete thought)
  ✗ "Load balancers" (missing period)

Do not use any tools. Generate based on context provided."""

    return prompt  # noqa: RET504


def call_claude(prompt: str, dry_run: bool = False, verbose: bool = False) -> dict[str, str] | None:
    """Call Claude Code CLI with the prompt using JSON output format.

    Args:
        prompt: The prompt to send to Claude
        dry_run: If True, print the prompt without calling Claude
        verbose: If True, print detailed debug information

    Returns:
        Dictionary with short/medium/long descriptions, or None on error
    """
    if dry_run:
        print(f"\n{'=' * 60}")
        print("DRY RUN: Would call claude -p with the following:")
        print(f"{'=' * 60}")
        print(f"\n[PROMPT]\n{prompt}\n")
        print(f"\n[JSON SCHEMA]\n{json.dumps(DESCRIPTION_SCHEMA, indent=2)}\n")
        return None

    # Build command with JSON output, schema validation, and MINIMAL config
    # Goal: Fast, cheap generation without loading MCP servers or tools
    cmd = [
        "claude",
        "-p",
        prompt,
        "--output-format",
        "json",
        "--json-schema",
        json.dumps(DESCRIPTION_SCHEMA),
        "--model",
        "haiku",  # Use haiku for fast, cheap generation
        "--no-session-persistence",  # Don't save session to disk
        "--append-system-prompt",
        "You are generating API descriptions. Respond ONLY with JSON matching the schema. Do not use any tools.",
    ]

    if verbose:
        print(f"\n[COMMAND]\n{' '.join(cmd[:4])} ...")
        print(f"\n[PROMPT]\n{prompt}\n")

    try:
        result = subprocess.run(
            cmd,
            check=False,
            capture_output=True,
            text=True,
            timeout=120,
        )

        if verbose:
            print(f"\n[RETURN CODE] {result.returncode}")
            if result.stderr:
                print(f"[STDERR]\n{result.stderr}")
            print(f"\n[STDOUT]\n{result.stdout[:1000]}...")

        if result.returncode != 0:
            print(f"Error: Claude CLI returned {result.returncode}")
            print(f"stderr: {result.stderr}")
            return None

        # Parse JSON response
        return parse_claude_output(result.stdout.strip(), verbose=verbose)

    except subprocess.TimeoutExpired:
        print("Error: Claude CLI timed out after 120 seconds")
        return None
    except FileNotFoundError:
        print("Error: 'claude' CLI not found. Please install Claude Code.")
        return None


def parse_claude_output(output: str, verbose: bool = False) -> dict[str, str] | None:
    """Parse JSON output from Claude Code CLI.

    The JSON response has structure:
    {
        "type": "result",
        "structured_output": {"short": ..., "medium": ..., "long": ...},
        ...
    }

    Args:
        output: Raw JSON string from Claude CLI
        verbose: If True, print debug information

    Returns:
        Dictionary with short/medium/long descriptions, or None on error
    """
    if not output:
        return None

    try:
        data = json.loads(output)

        if verbose:
            print(f"\n[PARSED JSON STRUCTURE]\n{json.dumps(data, indent=2)[:500]}...")

        # Claude JSON output with --json-schema puts result in "structured_output"
        result = data.get("structured_output")

        if result is None:
            # Fallback to "result" field for older format
            result = data.get("result", data)

        if not isinstance(result, dict):
            print(f"Error: Expected dict, got {type(result)}")
            if verbose:
                print(f"  Available keys: {list(data.keys())}")
            return None

        # Extract description tiers
        descriptions = {}
        for tier in ["short", "medium", "long"]:
            value = result.get(tier, "")
            if isinstance(value, str):
                descriptions[tier] = value.strip()

        if verbose:
            print("\n[EXTRACTED DESCRIPTIONS]")
            for tier, desc in descriptions.items():
                print(f"  {tier}: {desc[:60]}...")

        # Check for empty descriptions - reject if ALL tiers are empty or too short
        # This prevents {"short": "", "medium": "", "long": ""} from being treated as valid
        non_empty_count = sum(1 for v in descriptions.values() if v and len(v.split()) >= 3)
        if non_empty_count == 0:
            print("Error: All description tiers are empty or too short (less than 3 words)")
            if verbose:
                for tier, desc in descriptions.items():
                    word_count = len(desc.split()) if desc else 0
                    print(
                        f"  {tier}: {word_count} word(s) - '{desc[:50]}...' "
                        if desc
                        else f"  {tier}: empty",
                    )
            return None

        return descriptions if descriptions else None

    except json.JSONDecodeError as e:
        print(f"Error parsing Claude output as JSON: {e}")
        print(f"Raw output: {output[:500]}...")
        return None


def validate_descriptions(descriptions: dict[str, str]) -> dict[str, str]:
    """Validate descriptions for length and completeness.

    IMPORTANT: This function no longer truncates descriptions silently.
    Silent truncation was causing incomplete sentences. Instead, we:
    1. Warn about any issues but return descriptions unchanged
    2. Rely on validation checks in the retry loop to catch problems

    If descriptions exceed limits after all retries, they should be rejected
    rather than truncated, as truncation creates incomplete thoughts.

    Args:
        descriptions: Dictionary with short/medium/long descriptions

    Returns:
        Validated descriptions (unchanged - no truncation)
    """
    limits = {"short": MAX_SHORT, "medium": MAX_MEDIUM, "long": MAX_LONG}

    for tier, max_len in limits.items():
        value = descriptions.get(tier, "")
        text_stripped = value.rstrip()

        # Check length - warn but don't truncate
        if len(value) > max_len:
            print(
                f"  Warning: {tier} exceeds {max_len} chars ({len(value)} chars) - should have been caught earlier",
            )

        # Check for incomplete thoughts - warn but don't fix
        if text_stripped and not text_stripped.endswith((".", "!", "?")):
            print(f"  Warning: {tier} doesn't end with punctuation - may be incomplete thought")

    return descriptions


# =============================================================================
# 5-LAYER VALIDATION SYSTEM
# Based on research from Google, Microsoft, and OpenAPI best practices
# =============================================================================

# Layer 1: Regex-based Banned Patterns (word boundary matching)
BANNED_PATTERNS: list[tuple[str, str]] = [
    # Category 1: Redundant Terms (self-referential in API docs)
    (r"\bapi\b", "REDUNDANT: 'API' is self-referential in API specifications"),
    (r"\brest\s+api\b", "REDUNDANT: REST context is implicit"),
    (r"\bendpoint\b", "REDUNDANT: Endpoint context is implicit"),
    (r"\bspec(ification)?s?\b", "REDUNDANT: Meta-reference not allowed"),
    # Category 2: Brand/Product Terms (never allowed)
    (r"\bf5\b", "BRAND: F5 brand name not allowed"),
    (r"\b(f5[\s-]?)?xc\b", "BRAND: XC/F5 XC not allowed"),
    (r"\bdistributed\s+cloud\b", "BRAND: Product name not allowed"),
    (r"\bvolterra\b", "BRAND: Legacy brand not allowed"),
    # Category 3: Filler Words (add no meaning)
    (r"\butilize[sd]?\b", "FILLER: Use 'use' instead of 'utilize'"),
    (r"\bleverage[sd]?\b", "FILLER: Use 'use' instead of 'leverage'"),
    (r"\bfacilitate[sd]?\b", "FILLER: Use 'enable' instead of 'facilitate'"),
    (r"\bin order to\b", "FILLER: Use 'to' instead of 'in order to'"),
    (r"\bfor the purpose of\b", "FILLER: Use 'to' instead"),
    # Category 4: Vague Descriptors (be specific instead)
    (r"\bvarious\b", "VAGUE: Specify what types/items"),
    (r"\bmultiple\b", "VAGUE: Specify count or list items"),
    (r"\bseveral\b", "VAGUE: Specify count or list items"),
    (r"\betc\.?\b", "VAGUE: List explicitly or omit"),
    (r"\band more\b", "VAGUE: List explicitly or omit"),
    (r"\band so on\b", "VAGUE: List explicitly or omit"),
    (r"\bdiverse\b", "VAGUE: Specify what types"),
    (r"\bsundry\b", "VAGUE: Specify what items"),
    # Category 5: Marketing/Hype Words (remove promotional language)
    (r"\bseamless(ly)?\b", "MARKETING: Remove hype, state facts"),
    (r"\brobust\b", "MARKETING: Describe specific capabilities"),
    (r"\bpowerful\b", "MARKETING: Describe specific features"),
    (r"\bcutting[\s-]?edge\b", "MARKETING: Remove hype language"),
    (r"\brevolutionary\b", "MARKETING: Remove hype language"),
    (r"\benterprise[\s-]?grade\b", "MARKETING: Describe specific features"),
    (r"\bworld[\s-]?class\b", "MARKETING: Remove hype language"),
    (r"\bbest[\s-]?in[\s-]?class\b", "MARKETING: Remove hype language"),
    (r"\bunparalleled\b", "MARKETING: Remove hype language"),
    (r"\bsuperior\b", "MARKETING: Remove hype language"),
    (r"\binnovative\b", "MARKETING: Describe what it does instead"),
    (r"\bstate[\s-]?of[\s-]?the[\s-]?art\b", "MARKETING: Remove hype language"),
    # Category 6: Passive Voice Indicators
    (r"\bis returned\b", "PASSIVE: Use 'returns' (active voice)"),
    (r"\bare returned\b", "PASSIVE: Use 'return' (active voice)"),
    (r"\bis handled\b", "PASSIVE: Use 'handles' (active voice)"),
    (r"\bare handled\b", "PASSIVE: Use 'handle' (active voice)"),
    (r"\bis provided\b", "PASSIVE: Use 'provides' (active voice)"),
    (r"\bare provided\b", "PASSIVE: Use 'provide' (active voice)"),
    (r"\bis sent\b", "PASSIVE: Use 'sends' (active voice)"),
    (r"\bis used\b", "PASSIVE: Rewrite in active voice"),
    (r"\bis created\b", "PASSIVE: Use 'creates' (active voice)"),
    (r"\bis managed\b", "PASSIVE: Use 'manages' (active voice)"),
    # Category 7: Truncation Indicators (incomplete content)
    (r"\.\.\.", "TRUNCATED: Content was cut off - rewrite shorter"),
    (r"…", "TRUNCATED: Content was cut off - rewrite shorter"),
    # Category 8: Incomplete Sentence Indicators (complete thought validation)
    (
        r"\s(and|or|with|for|to|the|a|an)$",
        "INCOMPLETE: Sentence ends with conjunction/article - complete the thought",
    ),
    (r"[a-z]$", "INCOMPLETE: Sentence must end with punctuation (. ! ?) - not lowercase letter"),
    # Category 9: Redundant CRUD Action Words (implied in API context)
    # These verbs waste character budget since users already know it's a CRUD API
    (r"^Configure\s", "REDUNDANT_CRUD: 'Configure' is implied - start with noun/concept"),
    (r"^Manage\s", "REDUNDANT_CRUD: 'Manage' is implied - start with noun/concept"),
    (r"^Create\s", "REDUNDANT_CRUD: 'Create' is implied - describe what can be created"),
    (r"^Deploy\s", "REDUNDANT_CRUD: 'Deploy' is implied - describe what can be deployed"),
    (r"^Monitor\s", "REDUNDANT_CRUD: 'Monitor' is implied - describe what can be monitored"),
    (r"^Access\s", "REDUNDANT_CRUD: 'Access' is implied - describe what can be accessed"),
    (r"^Define\s", "REDUNDANT_CRUD: 'Define' is implied - describe what can be defined"),
    (r"^Set up\s", "REDUNDANT_CRUD: 'Set up' is implied - describe what can be set up"),
    (r"^Enable\s", "REDUNDANT_CRUD: 'Enable' is implied - describe what can be enabled"),
    (r"^Control\s", "REDUNDANT_CRUD: 'Control' is implied - describe what is controlled"),
    (r"^Handle\s", "REDUNDANT_CRUD: 'Handle' is implied - describe what is handled"),
    (r"^Automate\s", "REDUNDANT_CRUD: 'Automate' is implied - describe what is automated"),
]

# Layer 2: Self-Referential Suffixes (domain name + generic suffix = lazy)
SELF_REFERENTIAL_SUFFIXES = [
    "api",
    "apis",
    "service",
    "services",
    "system",
    "systems",
    "module",
    "modules",
    "interface",
    "interfaces",
    "endpoint",
    "endpoints",
    "operations",
    "functions",
    "methods",
    "calls",
    "features",
    "capabilities",
    "functionality",
]

# Bad starters (descriptions should NOT start with these - includes CRUD verbs which are implied)
BAD_STARTERS = [
    # Generic starters
    "this",
    "the ",
    "a ",
    "an ",
    "provides",
    "enables",
    "allows",
    "offers",
    "it ",
    "we ",
    # CRUD verbs (redundant in API context - implied that users will CRUD)
    "configure",
    "manage",
    "create",
    "deploy",
    "monitor",
    "access",
    "define",
    "set up",
    "enable",
    "control",
    "handle",
    "automate",
]

# Action verbs for short descriptions (positive pattern)
ACTION_VERBS = [
    # Core management verbs
    "manage",
    "configure",
    "monitor",
    "secure",
    "control",
    "analyze",
    "protect",
    "deploy",
    "automate",
    "enable",
    # Creation verbs
    "create",
    "define",
    "set",
    "establish",
    "build",
    # Traffic/routing verbs
    "route",
    "balance",
    "distribute",
    "cache",
    "filter",
    # Security verbs
    "detect",
    "block",
    "mitigate",
    "enforce",
    "validate",
    # Discovery/access verbs (valid for short descriptions)
    "discover",
    "connect",
    "access",
    "track",
    "inspect",
    "integrate",
    "orchestrate",
    "provision",
    "generate",
]


def is_self_referential(domain: str, desc: str) -> tuple[bool, str]:
    """Layer 2: Check if description merely restates domain + generic suffix.

    Args:
        domain: Domain name (e.g., "authentication", "data_intelligence")
        desc: Description text to check

    Returns:
        Tuple of (is_violation, error_message)
    """
    desc_lower = desc.lower().strip()
    domain_display = domain.replace("_", " ").lower()

    for suffix in SELF_REFERENTIAL_SUFFIXES:
        # Check exact match: "authentication api", "data intelligence service"
        if desc_lower == f"{domain_display} {suffix}":
            return True, f"LAZY: '{desc}' just restates domain name + '{suffix}'"
        # Check plural variations
        if desc_lower == f"{domain_display} {suffix}s":
            return True, f"LAZY: '{desc}' just restates domain name + '{suffix}s'"

    return False, ""


def validate_quality_metrics(desc: str, desc_type: str) -> list[str]:
    """Layer 3: Enforce character limits and quality standards.

    Args:
        desc: Description text to validate
        desc_type: One of 'short', 'medium', 'long'

    Returns:
        List of violation messages (empty if compliant)
    """
    errors: list[str] = []
    limits = {"short": MAX_SHORT, "medium": MAX_MEDIUM, "long": MAX_LONG}

    # Character limit check
    limit = limits.get(desc_type, MAX_LONG)
    if len(desc) > limit:
        errors.append(
            f"LENGTH: {len(desc)} chars exceeds {desc_type} limit of {limit}",
        )

    # Minimum content check (at least 3 words)
    word_count = len(desc.split())
    if word_count < 3:
        errors.append(f"SPARSE: Only {word_count} word(s) - needs at least 3")

    # NOTE: Action verb first check REMOVED (DRY-compliant)
    # CRUD verbs like Configure/Manage/Deploy are now BANNED because
    # they're implied in a CRUD API context. Descriptions should start
    # with nouns/concepts, not action verbs.

    return errors


def is_circular_definition(desc: str, tier: str = "long") -> tuple[bool, str]:
    """Layer 4: Detect definitions that repeat the same word excessively.

    Thresholds are tier-aware:
    - short: 2+ repetitions (very short, no room for repetition)
    - medium: 2+ repetitions (still short, minimal repetition)
    - long: 3+ repetitions (longer text, some repetition is natural)

    Args:
        desc: Description text to check
        tier: Description tier for threshold selection

    Returns:
        Tuple of (is_violation, error_message)
    """
    # Tier-aware thresholds
    threshold = {"short": 2, "medium": 2, "long": 3}.get(tier, 3)

    words = desc.lower().split()
    # Filter out small words
    significant_words = [w.strip(".,;:!?()[]{}\"'") for w in words if len(w) > 4]

    for word in set(significant_words):
        count = significant_words.count(word)
        if count >= threshold:
            return True, f"CIRCULAR: '{word}' appears {count} times - use variety"

    return False, ""


def check_domain_name_usage(domain: str, text: str, tier: str) -> Violation | None:
    """Check if description contains the domain name (self-reference).

    Returns a structured Violation with specific synonyms to use instead.

    Args:
        domain: Domain name to check against
        text: Description text to check
        tier: Description tier ('short', 'medium', 'long')

    Returns:
        Violation object if domain name found, None otherwise
    """
    domain_lower = domain.lower()
    domain_spaced = domain_lower.replace("_", " ")
    text_lower = text.lower()

    # Check both underscore and spaced versions
    for variant in [domain_lower, domain_spaced]:
        if variant in text_lower:
            # Find exact position for precise feedback
            start = text_lower.find(variant)
            exact_match = text[start : start + len(variant)]

            # Get domain-specific synonyms
            synonyms = DOMAIN_SYNONYMS.get(domain, ["infrastructure", "systems", "services"])

            return Violation(
                layer="self_referential",
                tier=tier,
                code="DOMAIN_NAME",
                message=f"Contains domain name '{domain}'",
                location=exact_match,
                suggestion=f"Replace '{exact_match}' with: {', '.join(synonyms[:3])}",
                examples=[f"Deploy {synonyms[0]} with configuration management"],
            )

    return None


def check_complete_thought(text: str, tier: str) -> list[Violation]:
    """Ensure description is a complete thought, not truncated or cut off.

    Validates that descriptions:
    1. End with proper sentence-ending punctuation (. ! ?)
    2. Don't end with conjunctions, prepositions, or articles
    3. Don't appear to be cut off mid-phrase

    Args:
        text: Description text to validate
        tier: Description tier ('short', 'medium', 'long')

    Returns:
        List of Violation objects for incomplete thought issues
    """
    violations: list[Violation] = []
    text_stripped = text.rstrip()

    if not text_stripped:
        return violations

    # Check 1: Must end with sentence-ending punctuation
    if not text_stripped.endswith((".", "!", "?")):
        violations.append(
            Violation(
                layer="quality",
                tier=tier,
                code="INCOMPLETE_THOUGHT",
                message="Description must end with period, exclamation, or question mark",
                location=text_stripped[-30:] if len(text_stripped) > 30 else text_stripped,
                suggestion="Complete the sentence with proper ending punctuation (.)",
                examples=["Configure load balancers with health checks."],
            ),
        )

    # Check 2: Detect cut-off patterns (articles, prepositions, conjunctions at end)
    cutoff_patterns = [
        (
            r"\s+(and|or|but|with|for|to|from|in|on|at|by|the|a|an)\s*$",
            "Ends with conjunction/preposition/article - sentence incomplete",
        ),
        (
            r"\s+\w{1,2}\s*$",
            "Ends with very short word (1-2 chars) - likely cut off",
        ),
    ]
    for pattern, message in cutoff_patterns:
        if re.search(pattern, text, re.IGNORECASE):
            violations.append(
                Violation(
                    layer="quality",
                    tier=tier,
                    code="CUTOFF_DETECTED",
                    message=message,
                    location=text[-40:] if len(text) > 40 else text,
                    suggestion="Complete the thought - don't end mid-phrase. Rewrite shorter if needed.",
                    examples=["Configure routing rules and health checks."],
                ),
            )
            break  # Only report one cutoff pattern

    return violations


def check_cross_tier_violations(descriptions: dict[str, str]) -> list[Violation]:
    """Check for excessive word overlap between description tiers.

    Returns structured Violations with specific words and synonym suggestions.

    Args:
        descriptions: Dictionary with short/medium/long descriptions

    Returns:
        List of Violation objects for cross-tier repetition issues
    """
    violations: list[Violation] = []

    short_words = set(_extract_significant_words(descriptions.get("short", "")))
    medium_words = set(_extract_significant_words(descriptions.get("medium", "")))
    long_words = set(_extract_significant_words(descriptions.get("long", "")))

    min_overlap_threshold = 4  # Only flag if >=4 significant words overlap

    # Check medium→long overlap (most common issue)
    medium_in_long = medium_words & long_words
    if len(medium_in_long) >= min_overlap_threshold:
        overlap_list = sorted(medium_in_long)
        # Generate synonym suggestions for the overlapping words
        synonym_hints = _get_synonym_hints(overlap_list[:4])

        violations.append(
            Violation(
                layer="cross_tier",
                tier="cross_tier",
                code="CROSS_TIER_OVERLAP",
                message=f"Medium and long share {len(medium_in_long)} significant words",
                location=", ".join(overlap_list[:6]),
                suggestion=f"In LONG tier, replace: {synonym_hints}",
                examples=[
                    "Use different vocabulary for each tier - add new concepts, not more of same",
                ],
            ),
        )

    # Check short→medium overlap
    short_in_medium = short_words & medium_words
    if len(short_in_medium) >= min_overlap_threshold:
        overlap_list = sorted(short_in_medium)
        synonym_hints = _get_synonym_hints(overlap_list[:4])

        violations.append(
            Violation(
                layer="cross_tier",
                tier="cross_tier",
                code="CROSS_TIER_OVERLAP",
                message=f"Short and medium share {len(short_in_medium)} significant words",
                location=", ".join(overlap_list[:6]),
                suggestion=f"In MEDIUM tier, replace: {synonym_hints}",
                examples=["Each tier should introduce new concepts"],
            ),
        )

    # Check short→long overlap
    short_in_long = short_words & long_words
    if len(short_in_long) >= min_overlap_threshold:
        overlap_list = sorted(short_in_long)
        synonym_hints = _get_synonym_hints(overlap_list[:4])

        violations.append(
            Violation(
                layer="cross_tier",
                tier="cross_tier",
                code="CROSS_TIER_OVERLAP",
                message=f"Short and long share {len(short_in_long)} significant words",
                location=", ".join(overlap_list[:6]),
                suggestion=f"In LONG tier, replace: {synonym_hints}",
                examples=["Long descriptions should add depth, not repeat short"],
            ),
        )

    return violations


def _get_synonym_hints(words: list[str]) -> str:
    """Generate synonym hints for overlapping words.

    Args:
        words: List of words that need synonyms

    Returns:
        String with word→synonym suggestions
    """
    # Common word synonyms for infrastructure/cloud domains
    synonyms = {
        "connections": "links, pathways, tunnels",
        "virtual": "software-defined, logical, cloud-based",
        "transit": "inter-region, cross-cloud, backbone",
        "azure": "cloud provider, hyperscaler",
        "configure": "set up, establish, define",
        "manage": "administer, control, oversee",
        "deploy": "provision, launch, instantiate",
        "security": "protection, safeguards, controls",
        "network": "connectivity, infrastructure, fabric",
        "traffic": "requests, data flow, packets",
        "routing": "path selection, forwarding, direction",
        "cluster": "node group, instance pool",
        "gateway": "entry point, ingress, proxy",
        "policy": "rule set, governance, constraints",
    }

    hints = []
    for word in words[:4]:
        word_lower = word.lower()
        if word_lower in synonyms:
            hints.append(f"'{word}' → {synonyms[word_lower]}")
        else:
            hints.append(f"'{word}' → (use synonym)")

    return "; ".join(hints)


MAX_RETRIES = 5  # Increased from 3 for better self-refine success rate


def check_banned_patterns(tier: str, text: str) -> list[str]:
    """Layer 1: Check for banned patterns using regex word boundaries.

    Args:
        tier: Description tier ('short', 'medium', 'long')
        text: Description text to check

    Returns:
        List of violation messages
    """
    violations: list[str] = []

    for pattern, error_msg in BANNED_PATTERNS:
        if re.search(pattern, text, re.IGNORECASE):
            # Find the actual matched text for better error reporting
            match = re.search(pattern, text, re.IGNORECASE)
            matched_text = match.group() if match else pattern
            violations.append(f"{tier}: {error_msg} (found: '{matched_text}')")

    return violations


def check_dry_compliance(domain: str, descriptions: dict[str, str]) -> list[str]:
    """Check for DRY violations in descriptions using 5-layer validation.

    Layers:
        1. Banned patterns (regex word boundaries)
        2. Self-referential detection (domain + suffix)
        3. Quality metrics (character limits, action verbs)
        4. Circular definitions
        5. Style compliance (bad starters)

    Args:
        domain: Domain name to check against
        descriptions: Dictionary with short/medium/long descriptions

    Returns:
        List of violation messages (empty if compliant)
    """
    violations: list[str] = []

    for tier, text in descriptions.items():
        if tier not in VALID_TIERS:
            continue  # Skip non-tier keys like source_patterns_hash
        # Layer 1: Check banned patterns with regex
        violations.extend(check_banned_patterns(tier, text))

        # Layer 2: Check self-referential patterns
        is_lazy, lazy_msg = is_self_referential(domain, text)
        if is_lazy:
            violations.append(f"{tier}: {lazy_msg}")

        # Layer 3: Quality metrics (character limits, action verbs)
        quality_errors = validate_quality_metrics(text, tier)
        violations.extend(f"{tier}: {err}" for err in quality_errors)

        # Layer 4: Circular definitions (tier-aware thresholds)
        is_circular, circular_msg = is_circular_definition(text, tier)
        if is_circular:
            violations.append(f"{tier}: {circular_msg}")

        # Check domain name (avoid self-reference) using structured check
        domain_violation = check_domain_name_usage(domain, text, tier)
        if domain_violation:
            violations.append(f"{tier}: Contains domain name '{domain}'")

    # Check cross-tier repetition using structured check
    cross_tier_violations = check_cross_tier_violations(descriptions)
    # Convert to string format for backward compatibility using extend
    violations.extend(f"Repetition: {v.message}: {{{v.location}}}" for v in cross_tier_violations)

    return violations


def run_all_validations_structured(domain: str, descriptions: dict[str, str]) -> list[Violation]:
    """Run all validation checks and return structured Violation objects.

    This is the new structured validation function that provides:
    - Exact location of problems
    - Specific fix suggestions
    - Concrete examples of correct alternatives

    Args:
        domain: Domain name to check against
        descriptions: Dictionary with short/medium/long descriptions

    Returns:
        List of Violation objects (empty if compliant)
    """
    violations: list[Violation] = []

    for tier, text in descriptions.items():
        # Layer 1: Check banned patterns
        for pattern, error_msg in BANNED_PATTERNS:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                matched_text = match.group()
                # Determine violation code from error message
                code = "BANNED_PATTERN"
                if "REDUNDANT" in error_msg:
                    code = "REDUNDANT"
                elif "BRAND" in error_msg:
                    code = "BRAND"
                elif "FILLER" in error_msg:
                    code = "FILLER"
                elif "VAGUE" in error_msg:
                    code = "VAGUE"
                elif "MARKETING" in error_msg:
                    code = "MARKETING"
                elif "PASSIVE" in error_msg:
                    code = "PASSIVE"
                elif "TRUNCATED" in error_msg:
                    code = "TRUNCATED"

                violations.append(
                    Violation(
                        layer="banned_patterns",
                        tier=tier,
                        code=code,
                        message=error_msg,
                        location=matched_text,
                        suggestion=error_msg.split(": ", 1)[-1]
                        if ": " in error_msg
                        else "Remove or replace this term",
                        examples=[],
                    ),
                )

        # Layer 2: Check self-referential patterns
        is_lazy, lazy_msg = is_self_referential(domain, text)
        if is_lazy:
            violations.append(
                Violation(
                    layer="self_referential",
                    tier=tier,
                    code="LAZY_PATTERN",
                    message=lazy_msg,
                    location=text,
                    suggestion="Write a functional description instead of restating the domain name",
                    examples=["Configure load distribution and traffic management"],
                ),
            )

        # Layer 3: Quality metrics
        limits = {"short": MAX_SHORT, "medium": MAX_MEDIUM, "long": MAX_LONG}
        limit = limits.get(tier, MAX_LONG)
        if len(text) > limit:
            violations.append(
                Violation(
                    layer="quality",
                    tier=tier,
                    code="LENGTH",
                    message=f"{len(text)} chars exceeds {tier} limit of {limit}",
                    location=f"Current: {len(text)} chars",
                    suggestion=f"Remove {len(text) - limit} characters - cut phrases like 'and policies', 'for distribution'",
                    examples=[],
                ),
            )

        word_count = len(text.split())
        if word_count < 3:
            violations.append(
                Violation(
                    layer="quality",
                    tier=tier,
                    code="SPARSE",
                    message=f"Only {word_count} word(s) - needs at least 3",
                    location=text,
                    suggestion="Add more descriptive content",
                    examples=["Configure load balancers and routing"],
                ),
            )

        # NOTE: Action verb check REMOVED (DRY-compliant)
        # CRUD verbs are now BANNED - descriptions should start with nouns/concepts
        # that describe what exists in the domain, not what operations are possible

        # Layer 4: Circular definitions
        is_circular, circular_msg = is_circular_definition(text, tier)
        if is_circular:
            violations.append(
                Violation(
                    layer="circular",
                    tier=tier,
                    code="CIRCULAR",
                    message=circular_msg,
                    location=text,
                    suggestion="Use variety - don't repeat significant words within the same tier",
                    examples=[],
                ),
            )

        # Check domain name
        domain_violation = check_domain_name_usage(domain, text, tier)
        if domain_violation:
            violations.append(domain_violation)

        # Layer 5: Complete thought validation (new)
        complete_thought_violations = check_complete_thought(text, tier)
        violations.extend(complete_thought_violations)

    # Check cross-tier repetition
    cross_tier_violations = check_cross_tier_violations(descriptions)
    violations.extend(cross_tier_violations)

    return violations


def _extract_significant_words(text: str) -> list[str]:
    """Extract significant words from text (excluding common stop words).

    Returns words that are meaningful for repetition detection.
    Excludes common technical terms that naturally appear across tiers.
    """
    stop_words = {
        # Common English stop words
        "a",
        "an",
        "the",
        "and",
        "or",
        "but",
        "in",
        "on",
        "at",
        "to",
        "for",
        "of",
        "with",
        "by",
        "from",
        "up",
        "about",
        "into",
        "through",
        "during",
        "is",
        "are",
        "was",
        "were",
        "be",
        "been",
        "being",
        "have",
        "has",
        "had",
        "do",
        "does",
        "did",
        "will",
        "would",
        "could",
        "should",
        "may",
        "might",
        "must",
        "shall",
        "can",
        "need",
        "dare",
        "ought",
        "used",
        "as",
        "if",
        "when",
        "than",
        "because",
        "while",
        "although",
        "where",
        "after",
        "so",
        "though",
        "since",
        "until",
        "unless",
        "that",
        "which",
        "who",
        "whom",
        "this",
        "these",
        "those",
        "it",
        "its",
        "their",
        "your",
        "our",
        "my",
        # Common action verbs (expected in all tiers)
        "configure",
        "create",
        "manage",
        "define",
        "deploy",
        "set",
        "use",
        "enable",
        "support",
        "include",
        "provide",
        "specify",
        "implement",
        "apply",
        "establish",
        "monitor",
        "control",
        "handle",
        "process",
        # Common technical terms (acceptable in multiple tiers)
        "rules",
        "policies",
        "settings",
        "options",
        "parameters",
        "values",
        "security",
        "protection",
        "traffic",
        "requests",
        "responses",
        "load",
        "balancer",
        "balancers",
        "balancing",
        "origin",
        "origins",
        "pool",
        "pools",
        "server",
        "servers",
        "service",
        "services",
        "application",
        "applications",
        "network",
        "networks",
        "cloud",
        "configuration",
        "configurations",
        "management",
        "routing",
        "health",
        "checks",
        "monitoring",
        "logging",
        "analytics",
        "authentication",
        "authorization",
        "access",
        "certificate",
        "certificates",
        "dns",
        "domain",
        "domains",
        "zone",
        "zones",
        "record",
        "records",
        "waf",
        "firewall",
        "bot",
        "rate",
        "limiting",
        "ddos",
        "mitigation",
        "api",
        "apis",
        "endpoint",
        "endpoints",
        "gateway",
        "gateways",
        "http",
        "https",
        "tcp",
        "tls",
        "ssl",
        "web",
        "data",
        "based",
        "multiple",
        "custom",
        "advanced",
        "automated",
        "automatic",
        # CDN-specific terms
        "content",
        "delivery",
        "caching",
        "cache",
        "cached",
        "edge",
        "edges",
        "distribution",
        "distributed",
        "latency",
        "performance",
        # DNS-specific terms
        "resolver",
        "resolvers",
        "lookup",
        "lookups",
        "query",
        "queries",
        "nameserver",
        "nameservers",
        "delegation",
        "propagation",
        # Attack/security-specific terms
        "attack",
        "attacks",
        "signature",
        "signatures",
        "detection",
        "threat",
        "threats",
        "malicious",
        "injection",
        "blocking",
    }

    words = text.lower().split()
    return [w.strip(".,;:!?()[]{}\"'") for w in words if len(w) > 4 and w.lower() not in stop_words]


def check_character_limits(descriptions: dict[str, str]) -> list[str]:
    """Check character limits without truncation.

    Args:
        descriptions: Dictionary with short/medium/long descriptions

    Returns:
        List of violation messages (empty if compliant)
    """
    violations = []
    limits = {"short": MAX_SHORT, "medium": MAX_MEDIUM, "long": MAX_LONG}

    for tier, limit in limits.items():
        text = descriptions.get(tier, "")
        if len(text) > limit:
            violations.append(f"{tier}: Exceeds {limit} chars ({len(text)} chars)")

    return violations


def check_style_compliance(descriptions: dict[str, str]) -> list[str]:
    """Check style compliance (active voice, verb-first, no bad starters).

    Args:
        descriptions: Dictionary with short/medium/long descriptions

    Returns:
        List of violation messages (empty if compliant)
    """
    violations = []

    for tier, text in descriptions.items():
        if tier not in VALID_TIERS:
            continue  # Skip non-tier keys like source_patterns_hash
        text_lower = text.lower().strip()

        # Check bad starters
        for starter in BAD_STARTERS:
            if text_lower.startswith(starter):
                violations.append(
                    f"{tier}: Starts with '{starter}' - should start with action verb",
                )
                break

    return violations


def check_complete_thought_string(descriptions: dict[str, str]) -> list[str]:
    """Check for complete thought violations, returning string messages.

    This is the string-format version of check_complete_thought() for
    backward compatibility with run_all_validations().

    Args:
        descriptions: Dictionary with short/medium/long descriptions

    Returns:
        List of violation messages (empty if compliant)
    """
    violations: list[str] = []
    for tier, text in descriptions.items():
        if tier not in VALID_TIERS:
            continue  # Skip non-tier keys like source_patterns_hash
        tier_violations = check_complete_thought(text, tier)
        violations.extend(f"{tier}: {v.message}" for v in tier_violations)
    return violations


def run_all_validations(domain: str, descriptions: dict[str, str]) -> list[str]:
    """Run all validation checks on descriptions.

    Args:
        domain: Domain name
        descriptions: Dictionary with short/medium/long descriptions

    Returns:
        Combined list of all violations
    """
    violations = []
    violations.extend(check_dry_compliance(domain, descriptions))
    violations.extend(check_character_limits(descriptions))
    violations.extend(check_style_compliance(descriptions))
    violations.extend(check_complete_thought_string(descriptions))
    return violations


def build_refinement_prompt(
    domain: str,
    context: dict[str, Any],
    previous_response: dict[str, str],
    violations: list[str] | list[Violation],
) -> str:
    """Build a refinement prompt with specific, actionable feedback.

    Instead of retrying with the same prompt, this provides the model with:
    - The previous response that failed
    - Specific violations with concrete fix instructions
    - Exact words to replace and suggested alternatives
    - Domain-specific synonym suggestions

    This implements the Self-Refine approach which achieves 85-95% compliance
    vs ~50% for blind retries.

    Args:
        domain: Domain name being processed
        context: Domain context dictionary
        previous_response: The descriptions that failed validation
        violations: List of Violation objects OR legacy string messages

    Returns:
        Refined prompt with specific feedback
    """
    # Handle both structured Violation objects and legacy string format
    feedback_items = []
    limits = {"short": MAX_SHORT, "medium": MAX_MEDIUM, "long": MAX_LONG}

    for violation in violations:
        if isinstance(violation, Violation):
            # Use structured violation data for precise feedback
            feedback_items.append(violation.to_feedback())
        else:
            # Legacy string handling for backward compatibility
            v_lower = violation.lower()
            tier = violation.split(":")[0].lower() if ":" in violation else ""

            if "exceeds" in v_lower:
                try:
                    current_chars = int(violation.split("(")[1].split()[0])
                    max_chars = limits.get(tier, 500)
                    reduction = current_chars - max_chars
                    pct = (reduction * 100) // current_chars
                    feedback_items.append(
                        f"❌ {tier.upper()}: {current_chars} chars → max {max_chars}. "
                        f"REMOVE {reduction} chars ({pct}% reduction). "
                        f"Cut phrases like 'and policies', 'for distribution', etc.",
                    )
                except (IndexError, ValueError):
                    feedback_items.append(f"❌ {violation} - SHORTEN this tier")
            elif "banned term" in v_lower:
                try:
                    term = violation.split("'")[1]
                    alternatives = {
                        "comprehensive": "broad",
                        "complete": "full-featured",
                        "extensive": "wide-ranging",
                        "specifications": "definitions",
                        "spec": "definition",
                        "api": "interface",
                        "endpoint": "path",
                    }
                    alt = alternatives.get(term.lower(), "(remove entirely)")
                    feedback_items.append(
                        f"❌ {tier.upper()}: Remove banned term '{term}'. Alternative: {alt}",
                    )
                except IndexError:
                    feedback_items.append(f"❌ {violation}")
            elif "domain name" in v_lower:
                # Get domain synonyms for better suggestions
                synonyms = DOMAIN_SYNONYMS.get(domain, ["infrastructure", "systems", "services"])
                feedback_items.append(
                    f"❌ {tier.upper()}: Contains domain name '{domain}'. "
                    f"Replace with: {', '.join(synonyms[:3])}",
                )
            elif "starts with" in v_lower:
                try:
                    starter = violation.split("'")[1]
                    feedback_items.append(
                        f"❌ {tier.upper()}: Starts with '{starter}'. "
                        f"MUST start with NOUN/CONCEPT (not CRUD verbs). "
                        f"Example: 'HTTP load balancing...' not 'Configure load balancing...'",
                    )
                except IndexError:
                    feedback_items.append(f"❌ {violation}")
            elif "repetition" in v_lower or "overlap" in v_lower:
                feedback_items.append(
                    f"❌ {violation}. Use DIFFERENT vocabulary in each tier.",
                )
            else:
                feedback_items.append(f"❌ {violation}")

    feedback_str = "\n".join(feedback_items)
    prev_json = json.dumps(previous_response, indent=2)

    # Current character counts for reference
    char_counts = {
        tier: len(previous_response.get(tier, "")) for tier in ["short", "medium", "long"]
    }
    counts_str = ", ".join(f"{t}: {c}" for t, c in char_counts.items())

    # Get domain synonyms to help the model avoid domain name
    domain_synonyms = DOMAIN_SYNONYMS.get(domain, ["infrastructure", "systems", "services"])
    synonyms_str = ", ".join(domain_synonyms[:5])

    return f"""Your previous response for "{context["domain_title"]}" domain FAILED validation.

PREVIOUS RESPONSE (char counts: {counts_str}):
{prev_json}

═══════════════════════════════════════════════════════════════════════════════
SPECIFIC VIOLATIONS TO FIX:
{feedback_str}

═══════════════════════════════════════════════════════════════════════════════
DOMAIN-SPECIFIC GUIDANCE:

NEVER use the word "{domain.replace("_", " ")}" in any description.
Instead, use these synonyms: {synonyms_str}

═══════════════════════════════════════════════════════════════════════════════
FIX INSTRUCTIONS:

1. For DOMAIN NAME violations:
   - Replace "{domain.replace("_", " ")}" with one of: {synonyms_str}
   - The description DESCRIBES the domain, it should NOT MENTION it

2. For CHARACTER LIMIT violations:
   - SHORT must be ≤{MAX_SHORT} chars (aim for 35-50)
   - MEDIUM must be ≤{MAX_MEDIUM} chars (aim for 100-130)
   - LONG must be ≤{MAX_LONG} chars (aim for 350-450)
   - Remove words/phrases, don't truncate with "..."

3. For REPETITION/OVERLAP violations:
   - Each tier must use DIFFERENT vocabulary
   - Replace overlapping words with synonyms
   - Progress: WHAT (short) → HOW+SCOPE (medium) → WHERE+WHEN+METRICS (long)

4. For STYLE violations (DRY-COMPLIANT):
   - Start EVERY tier with NOUN/CONCEPT (not action verbs)
   - BANNED: Configure, Create, Manage, Define, Deploy, Monitor, Access
   - Also banned: This, The, A, An, Provides, Enables
   - Example: "HTTP load balancing..." NOT "Configure load balancing..."

═══════════════════════════════════════════════════════════════════════════════
OUTPUT:

Respond with CORRECTED JSON only. Fix ALL violations listed above.
{{"short": "...", "medium": "...", "long": "..."}}

Do not use any tools. Generate corrected output based on the feedback."""


def create_violation_issue(
    domain: str,
    violations: list[str],
    prompt: str,
    response: str,
) -> bool:
    """Create GitHub issue when generation fails validation after retries.

    Args:
        domain: Domain that failed validation
        violations: List of violation messages
        prompt: The prompt that was used
        response: The response that was generated

    Returns:
        True if issue was created successfully
    """
    timestamp = datetime.now(tz=timezone.utc).isoformat()
    violations_list = "\n".join(f"- {v}" for v in violations)

    # Truncate prompt for readability (keep first 2000 chars)
    prompt_truncated = prompt[:2000] + "..." if len(prompt) > 2000 else prompt

    title = f"Description generation violation: {domain}"
    body = f"""## Violation Report

**Domain**: `{domain}`
**Timestamp**: {timestamp}
**Retry Attempts**: {MAX_RETRIES}

### Violations Detected

{violations_list}

### Prompt Used

```
{prompt_truncated}
```

### Generated Response

```json
{response}
```

### Expected Behavior

Descriptions should:
- Not contain F5/XC/Distributed Cloud references
- Not mention domain name in own description
- Fit within character limits without truncation (60/150/500)
- Start with action verbs (Configure, Create, Manage, etc.)
- Have no cross-tier repetition

### Next Steps

1. Analyze why the prompt failed to produce compliant output
2. Update `build_prompt()` in `scripts/generate_descriptions.py` with refined instructions
3. Re-test with this domain: `python -m scripts.generate_descriptions --domain {domain} --force`

---
🤖 Generated automatically by description generation script
"""

    try:
        # Create issue without labels (labels may not exist in repo)
        result = subprocess.run(
            [
                "gh",
                "issue",
                "create",
                "--title",
                title,
                "--body",
                body,
            ],
            capture_output=True,
            text=True,
            check=False,
        )

        if result.returncode == 0:
            print(f"  ✓ Created GitHub issue: {result.stdout.strip()}")
            return True
        print(f"  Warning: Failed to create GitHub issue: {result.stderr}")
        return False

    except FileNotFoundError:
        print("  Warning: 'gh' CLI not found. Cannot create GitHub issue.")
        return False


def generate_for_domain(
    domain: str,
    config: dict[str, Any],
    force: bool = False,
    dry_run: bool = False,
    verbose: bool = False,
) -> bool:
    """Generate descriptions for a single domain with validation and retry.

    Uses a retry loop (up to MAX_RETRIES attempts) to ensure descriptions
    meet all DRY, character limit, and style requirements. Creates a GitHub
    issue for prompt refinement if all retries are exhausted.

    Args:
        domain: Domain name to generate descriptions for
        config: Configuration dictionary to update
        force: If True, regenerate even if descriptions exist
        dry_run: If True, show prompt without calling Claude
        verbose: If True, show detailed debug output

    Returns:
        True if successful, False otherwise
    """
    print(f"\n{'=' * 60}")
    print(f"Processing domain: {domain}")
    print(f"{'=' * 60}")

    # Compute current source patterns hash for change detection
    current_hash = compute_source_patterns_hash(domain)

    # Check if already configured and whether source specs have changed
    existing_config = config.get("domains", {}).get(domain, {})
    if existing_config and not force:
        stored_hash = existing_config.get("source_patterns_hash")
        if stored_hash == current_hash:
            print("  Skipping: descriptions exist and source specs unchanged")
            return True
        if stored_hash:
            print("  Source specs changed (hash mismatch), regenerating...")
        else:
            print("  Skipping: descriptions already exist (use --force to regenerate)")
            return True

    # Gather context
    context = get_domain_context(domain)
    if context.get("spec_count", 0) == 0:
        print(f"  Warning: No source specs found for domain '{domain}'")

    # Build prompt
    prompt = build_prompt(domain, context)
    print(
        f"  Context gathered: {context.get('spec_count', 0)} specs, {len(context.get('paths', []))} paths",
    )

    if dry_run:
        print(f"\n{'=' * 60}")
        print("DRY RUN: Would call claude -p with the following:")
        print(f"{'=' * 60}")
        print(f"\n[PROMPT]\n{prompt}\n")
        return True

    # Self-refine loop with specific feedback (not blind retry)
    # Research shows self-refine achieves 85-95% compliance vs ~50% for blind retries
    last_descriptions = None
    last_response = ""
    violations = []
    current_prompt = prompt  # Start with initial prompt, switch to refinement on retry

    for attempt in range(1, MAX_RETRIES + 1):
        print(f"  Attempt {attempt}/{MAX_RETRIES}: Calling Claude Code CLI...")
        descriptions = call_claude(current_prompt, dry_run=False, verbose=verbose)

        if not descriptions:
            print(f"  Attempt {attempt}: No descriptions returned from Claude")
            continue

        last_descriptions = descriptions
        last_response = json.dumps(descriptions, indent=2)

        # Run all validations
        violations = run_all_validations(domain, descriptions)

        if not violations:
            print(f"  ✓ Attempt {attempt}: All validations passed")
            break

        # Print violations with character counts for transparency
        char_info = ", ".join(
            f"{t}: {len(descriptions.get(t, ''))}" for t in ["short", "medium", "long"]
        )
        print(f"  Attempt {attempt}: {len(violations)} violation(s) detected (chars: {char_info}):")
        for v in violations[:5]:  # Show first 5 violations
            print(f"    - {v}")
        if len(violations) > 5:
            print(f"    ... and {len(violations) - 5} more")

        if attempt < MAX_RETRIES:
            # Build refinement prompt with specific feedback (Self-Refine approach)
            current_prompt = build_refinement_prompt(domain, context, descriptions, violations)
            print("  Building refinement prompt with specific feedback...")

    # Check if we succeeded
    if violations:
        print(f"\n  ✗ All {MAX_RETRIES} attempts failed validation. Creating GitHub issue...")
        create_violation_issue(domain, violations, prompt, last_response)
        return False

    if not last_descriptions:
        print("  Error: No valid descriptions generated after all attempts")
        return False

    # Validate lengths (truncate if needed, but this shouldn't happen with good prompts)
    descriptions = validate_descriptions(last_descriptions)

    # Update config with descriptions and source hash for change detection
    if "domains" not in config:
        config["domains"] = {}

    config["domains"][domain] = {
        "source_patterns_hash": current_hash,
        "short": descriptions.get("short", ""),
        "medium": descriptions.get("medium", ""),
        "long": descriptions.get("long", ""),
    }

    print("  Generated descriptions:")
    print(
        f"    short ({len(descriptions.get('short', ''))} chars): {descriptions.get('short', '')}",
    )
    print(
        f"    medium ({len(descriptions.get('medium', ''))} chars): {descriptions.get('medium', '')}",
    )
    print(
        f"    long ({len(descriptions.get('long', ''))} chars): {descriptions.get('long', '')[:150]}...",
    )

    return True


def get_all_domains() -> list[str]:
    """Get all domains from domain patterns config."""
    categorizer = DomainCategorizer()
    return categorizer.get_all_domains()


def main() -> int:
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="Generate enriched domain descriptions using Claude Code CLI",
    )
    parser.add_argument(
        "--domain",
        help="Generate for specific domain (e.g., 'virtual', 'dns')",
    )
    parser.add_argument(
        "--all",
        action="store_true",
        help="Generate for all domains without existing descriptions",
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="Force regeneration even if descriptions exist",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Show prompts without calling Claude",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Show detailed debug output (prompt, command, response)",
    )
    parser.add_argument(
        "--list",
        action="store_true",
        help="List all domains and their description status",
    )

    args = parser.parse_args()

    # Load existing config
    config = load_config()
    existing_domains = set(config.get("domains", {}).keys())

    if args.list:
        all_domains = get_all_domains()
        print(
            f"\nDomain Description Status ({len(existing_domains)}/{len(all_domains)} configured):",
        )
        print("=" * 60)
        for domain in sorted(all_domains):
            status = "✓" if domain in existing_domains else "✗"
            print(f"  {status} {domain}")
        return 0

    if not args.domain and not args.all:
        parser.error("Either --domain or --all is required (or use --list)")

    # Determine domains to process
    if args.all:
        all_domains = get_all_domains()
        domains_to_process = [d for d in all_domains if d not in existing_domains or args.force]
        print(f"\nProcessing {len(domains_to_process)} domains...")
    else:
        domains_to_process = [args.domain]

    # Process domains
    success_count = 0
    for domain in domains_to_process:
        if generate_for_domain(
            domain,
            config,
            force=args.force,
            dry_run=args.dry_run,
            verbose=args.verbose,
        ):
            success_count += 1

    # Save config (unless dry run)
    if not args.dry_run and success_count > 0:
        save_config(config)
        print(f"\n✓ Saved {success_count} descriptions to {CONFIG_PATH}")

    print(f"\nCompleted: {success_count}/{len(domains_to_process)} domains processed successfully")
    return 0 if success_count == len(domains_to_process) else 1


if __name__ == "__main__":
    sys.exit(main())
