name: Sync and Enrich API Specs

on:
  schedule:
    # Run daily at 6 AM UTC
    - cron: '0 6 * * *'
  push:
    branches:
      - main
    paths:
      - 'scripts/**'
      - 'config/**'
      - 'requirements.txt'
      - '.github/workflows/sync-and-enrich.yml'
      - 'docs/**/*.html'
  workflow_dispatch:

permissions:
  contents: write
  pages: write
  id-token: write
  issues: write
  actions: read

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: '3.13'

jobs:
  check-updates:
    name: Check for Updates
    runs-on: ubuntu-latest
    outputs:
      has_updates: ${{ steps.check.outputs.updated }}
      etag: ${{ steps.check.outputs.etag }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6

      - name: Setup Python
        uses: actions/setup-python@v6
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Check for updates
        id: check
        run: |
          # Force download on push/dispatch events, check-only on schedule
          if [ "${{ github.event_name }}" = "push" ] || \
             [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "updated=true" >> "$GITHUB_OUTPUT"
            echo "Push/dispatch event - forcing download"
          else
            python -m scripts.download --check-only
          fi

  sync-and-enrich:
    name: Sync and Enrich Specifications
    needs: check-updates
    if: needs.check-updates.outputs.has_updates == 'true'
    runs-on: ubuntu-latest
    outputs:
      version: ${{ steps.version.outputs.new_version }}
      has_changes: ${{ steps.version.outputs.has_changes }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6
        with:
          fetch-depth: 2  # Need previous commit for diff

      - name: Setup Python
        uses: actions/setup-python@v6
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          # Install Java for LanguageTool (grammar checking)
          sudo apt-get update
          sudo apt-get install -y default-jre

      - name: Setup Node.js for Spectral
        uses: actions/setup-node@v6
        with:
          node-version: '22'

      - name: Install Spectral CLI
        run: npm install -g @stoplight/spectral-cli

      - name: Download specifications
        run: python -m scripts.download --force

      - name: Check for Discovery Data
        id: check-discovery
        run: |
          # Check for session.json (metadata) since openapi.json is gitignored due to size
          if [ -f "specs/discovered/session.json" ]; then
            echo "has_discovery=true" >> "$GITHUB_OUTPUT"
            echo "::notice::Discovery session found - discovery enrichment available locally"
          else
            echo "has_discovery=false" >> "$GITHUB_OUTPUT"
            echo "No discovery data - running standard enrichment"
          fi
          # Check for full openapi.json (required for constraint analysis)
          # This is gitignored due to 26MB size, only available when run locally
          if [ -f "specs/discovered/openapi.json" ]; then
            echo "has_full_discovery=true" >> "$GITHUB_OUTPUT"
          else
            echo "has_full_discovery=false" >> "$GITHUB_OUTPUT"
            echo "::notice::Full discovery openapi.json not available - constraint analysis skipped"
          fi

      - name: Run enrichment pipeline
        run: python -m scripts.pipeline
        env:
          DISCOVERY_ENRICHMENT_ENABLED: ${{ steps.check-discovery.outputs.has_discovery }}

      - name: Generate constraint analysis report
        if: steps.check-discovery.outputs.has_full_discovery == 'true'
        run: python -m scripts.analyze_constraints

      - name: Lint specifications with Spectral
        run: python scripts/lint.py --input-dir docs/specifications/api --fail-on-error --fail-on-warning

      - name: Validate specifications
        continue-on-error: true
        env:
          F5XC_API_TOKEN: ${{ secrets.F5XC_API_TOKEN }}
          F5XC_API_URL: ${{ secrets.F5XC_API_URL }}
        run: python -m scripts.validate --dry-run

      - name: Early exit for docs-only changes
        id: docs_check
        run: |
          echo "Checking for documentation-only changes..."

          # Check if ALL changes are docs-only using git pathspec exclusion
          if git diff --quiet HEAD~1 HEAD -- . ':!CLAUDE.md' ':!README.md' ':!docs/**/*.md' ':!LICENSE'; then
            echo "ðŸ“ Documentation-only changes detected - skipping pipeline"
            echo "has_changes=false" >> "$GITHUB_OUTPUT"
            exit 0
          else
            echo "âœ… Non-documentation changes detected - proceeding with pipeline"
          fi

      - name: Detect changes and bump version
        id: version
        run: |
          # Check if enriched specs exist (pipeline generated them)
          if [ ! -f docs/specifications/api/index.json ]; then
            echo "has_changes=false" >> "$GITHUB_OUTPUT"
            echo "No enriched specs generated"
            exit 0
          fi

          # Compare with previous release or mark as changed for new runs
          # Check for changes in source specs, pipeline config, or dependencies
          if git diff --quiet HEAD~1 HEAD -- \
            specs/original/ .etag scripts/ config/ requirements.txt \
            .github/workflows/sync-and-enrich.yml; then
            echo "has_changes=false" >> "$GITHUB_OUTPUT"
            echo "â­ï¸  No changes in: specs, pipeline scripts, configs, or workflow"
            exit 0
          fi

          echo "has_changes=true" >> "$GITHUB_OUTPUT"

          # Determine change type for semantic versioning (as bash variable for use in this script)
          if ! git diff --quiet HEAD~1 HEAD -- specs/original/ .etag; then
            CHANGE_TYPE="source"
            echo "Source spec changes detected"
          elif ! git diff --quiet HEAD~1 HEAD -- \
            config/ scripts/ requirements.txt \
            .github/workflows/sync-and-enrich.yml; then
            CHANGE_TYPE="pipeline"
            echo "Pipeline/config/workflow changes detected"
          else
            CHANGE_TYPE="unknown"
            echo "Unknown change type"
          fi

          # Output change type for downstream steps
          echo "change_type=$CHANGE_TYPE" >> "$GITHUB_OUTPUT"

          # Verify .version file integrity
          if [ ! -f .version ]; then
            echo "::error::.version file missing - cannot determine version"
            exit 1
          fi

          TEMP_VERSION=$(cat .version 2>/dev/null || echo "0.0.0")
          if ! [[ "$TEMP_VERSION" =~ ^[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
            echo "::error::Invalid version format in .version: $TEMP_VERSION"
            exit 1
          fi

          echo "âœ… Current version validated: $TEMP_VERSION"

          # Read current version
          CURRENT_VERSION=$(cat .version 2>/dev/null | tr -d '[:space:]')
          echo "current_version=$CURRENT_VERSION" >> "$GITHUB_OUTPUT"

          # Determine bump type (always auto since workflow_dispatch removed)
          BUMP_TYPE="auto"

          # Migration check: if not semver format, start at 1.0.0
          if [[ ! "$CURRENT_VERSION" =~ ^[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
            NEW_VERSION="1.0.0"
            BUMP_TYPE="migration"
          elif [ "$BUMP_TYPE" = "auto" ]; then
            IFS='.' read -r MAJOR MINOR PATCH <<< "$CURRENT_VERSION"

            # Check for major bump via commit message (highest priority)
            COMMIT_MSG=$(git log -1 --pretty=%B 2>/dev/null || echo "")
            if [[ "$COMMIT_MSG" == *"[major]"* ]] || \
               [[ "$COMMIT_MSG" == *"BREAKING CHANGE"* ]]; then
              NEW_VERSION="$((MAJOR + 1)).0.0"
              BUMP_TYPE="major"
            elif [ "$CHANGE_TYPE" = "source" ]; then
              # Source spec changes â†’ check for new domains (minor) or patch
              PREV_COUNT=$(git show HEAD:docs/specifications/api/index.json 2>/dev/null | \
                jq '.specifications | length' 2>/dev/null || echo "0")
              CURR_COUNT=$(jq '.specifications | length' \
                docs/specifications/api/index.json 2>/dev/null || echo "0")

              if [ "$CURR_COUNT" -gt "$PREV_COUNT" ]; then
                NEW_VERSION="${MAJOR}.$((MINOR + 1)).0"
                BUMP_TYPE="minor"
              else
                NEW_VERSION="${MAJOR}.${MINOR}.$((PATCH + 1))"
                BUMP_TYPE="patch"
              fi
            elif [ "$CHANGE_TYPE" = "pipeline" ]; then
              # Pipeline/config/dependency changes â†’ patch bump
              NEW_VERSION="${MAJOR}.${MINOR}.$((PATCH + 1))"
              BUMP_TYPE="patch"
              echo "::notice::Pipeline changes detected - patch bump"
            else
              # Fallback for unknown change types
              NEW_VERSION="${MAJOR}.${MINOR}.$((PATCH + 1))"
              BUMP_TYPE="patch"
              echo "::warning::Unknown change type - defaulting to patch bump"
            fi
          else
            # Manual bump type
            IFS='.' read -r MAJOR MINOR PATCH <<< "$CURRENT_VERSION"
            case "$BUMP_TYPE" in
              major) NEW_VERSION="$((MAJOR + 1)).0.0" ;;
              minor) NEW_VERSION="${MAJOR}.$((MINOR + 1)).0" ;;
              patch) NEW_VERSION="${MAJOR}.${MINOR}.$((PATCH + 1))" ;;
            esac
          fi

          echo "new_version=$NEW_VERSION" >> "$GITHUB_OUTPUT"
          echo "bump_type=$BUMP_TYPE" >> "$GITHUB_OUTPUT"

          # Update .version file
          echo "$NEW_VERSION" > .version

          echo "::notice::Version: $CURRENT_VERSION -> $NEW_VERSION ($BUMP_TYPE)"

      - name: Update version in specs
        if: steps.version.outputs.has_changes == 'true'
        run: |
          VERSION="${{ steps.version.outputs.new_version }}"

          # Update index.json
          jq --arg v "$VERSION" '.version = $v' docs/specifications/api/index.json > /tmp/index.json
          mv /tmp/index.json docs/specifications/api/index.json

          # Update all domain specs
          for spec in docs/specifications/api/*.json; do
            if [ "$(basename "$spec")" != "index.json" ]; then
              jq --arg v "$VERSION" '.info.version = $v' "$spec" > /tmp/spec.json
              mv /tmp/spec.json "$spec"
            fi
          done

      - name: Generate discovery summary
        id: discovery-summary
        if: steps.check-discovery.outputs.has_discovery == 'true'
        run: |
          if [ -f "specs/discovered/session.json" ]; then
            ENDPOINTS=$(jq -r '.statistics.endpoints_total // 0' specs/discovered/session.json)
            SUCCESS=$(jq -r '.statistics.endpoints_successful // 0' specs/discovered/session.json)
            TIMESTAMP=$(jq -r '.started_at // "unknown"' specs/discovered/session.json)
            {
              echo "endpoints_total=$ENDPOINTS"
              echo "endpoints_success=$SUCCESS"
              echo "discovery_timestamp=$TIMESTAMP"
            } >> "$GITHUB_OUTPUT"
            echo "::notice::Discovery: ${SUCCESS}/${ENDPOINTS} endpoints discovered at ${TIMESTAMP}"
          fi

      - name: Generate changelog
        if: steps.version.outputs.has_changes == 'true'
        run: |
          VERSION="${{ steps.version.outputs.new_version }}"
          BUMP_TYPE="${{ steps.version.outputs.bump_type }}"
          DATE=$(date -u +"%Y-%m-%d")

          # Extract upstream info from index.json
          UPSTREAM_TS=$(jq -r '."x-upstream-timestamp" // "unknown"' docs/specifications/api/index.json)
          UPSTREAM_ETAG=$(jq -r '."x-upstream-etag" // "unknown"' docs/specifications/api/index.json)
          ENRICHED_VER=$(jq -r '."x-enriched-version" // "'$VERSION'"' docs/specifications/api/index.json)
          FULL_VERSION=$(jq -r '.version' docs/specifications/api/index.json)

          # Discovery info (if available)
          HAS_DISCOVERY="${{ steps.check-discovery.outputs.has_discovery }}"
          DISCOVERY_ENDPOINTS="${{ steps.discovery-summary.outputs.endpoints_total }}"
          DISCOVERY_SUCCESS="${{ steps.discovery-summary.outputs.endpoints_success }}"
          DISCOVERY_TIMESTAMP="${{ steps.discovery-summary.outputs.discovery_timestamp }}"

          cat > CHANGELOG.md << EOF
          # Changelog

          ## Version $FULL_VERSION ($DATE)

          ### Version Information
          | Field | Value |
          |-------|-------|
          | Full Version | $FULL_VERSION |
          | Upstream Timestamp | $UPSTREAM_TS |
          | Upstream ETag | $UPSTREAM_ETAG |
          | Enriched Version | $ENRICHED_VER |

          ### Release Type
          - **$BUMP_TYPE** release

          ### Changes
          - Updated API specifications from F5 Distributed Cloud
          - Applied enrichment pipeline:
            - Acronym normalization (100+ terms)
            - Grammar improvements
            - Branding updates (Volterra â†’ F5 Distributed Cloud)
          - Applied normalization pipeline:
            - Fixed orphan \$ref references
            - Removed empty operations
            - Type standardization
          - Validated with Spectral OpenAPI linter
          - Merged specifications by domain

          ### Statistics
          - Original specs: $(find specs/original -name '*.json' 2>/dev/null | wc -l | xargs)
          - Domains: $(jq '.specifications | length' docs/specifications/api/index.json)
          - Total paths: $(jq '[.specifications[].path_count] | add' docs/specifications/api/index.json)
          - Total schemas: $(jq '[.specifications[].schema_count] | add' docs/specifications/api/index.json)
          EOF

          # Add discovery section if available
          if [ "$HAS_DISCOVERY" = "true" ] && [ -n "$DISCOVERY_ENDPOINTS" ]; then
            cat >> CHANGELOG.md << EOF

          ### API Discovery Enrichment
          - Discovery timestamp: $DISCOVERY_TIMESTAMP
          - Endpoints explored: $DISCOVERY_SUCCESS / $DISCOVERY_ENDPOINTS
          - Applied x-discovered-* extensions from live API exploration
          - See \`reports/constraint-analysis.md\` for detailed comparison
          EOF
          fi

          cat >> CHANGELOG.md << EOF

          ### Output Structure
          \`\`\`text
          docs/specifications/api/
          â”œâ”€â”€ [domain].json        # Domain-specific specs
          â”œâ”€â”€ openapi.json         # Master combined spec
          â””â”€â”€ index.json           # Metadata index
          \`\`\`

          ### Download
          - ZIP Package: F5xc-api-(${UPSTREAM_TS}-${ENRICHED_VER}).zip

          ### Source
          - Source: F5 Distributed Cloud OpenAPI specifications
          - Upstream: $UPSTREAM_TS (ETag: $UPSTREAM_ETAG)
          EOF

      - name: Upload docs artifact for deployment
        if: steps.version.outputs.has_changes == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: docs-site
          path: docs
          retention-days: 1

      - name: Commit changes
        if: steps.version.outputs.has_changes == 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          # Only add files that are tracked (specs/original is gitignored)
          git add .version CHANGELOG.md .etag

          if git diff --staged --quiet; then
            echo "No changes to commit"
            exit 0
          fi

          VERSION="${{ steps.version.outputs.new_version }}"
          BUMP_TYPE="${{ steps.version.outputs.bump_type }}"

          git commit -m "chore: update API specifications to v$VERSION

          - Version bump: $BUMP_TYPE
          - Downloaded latest specifications from F5 Distributed Cloud
          - Applied unified enrichment pipeline
          - Updated documentation portal"

      - name: Push changes
        if: steps.version.outputs.has_changes == 'true'
        run: git push

      - name: Create release package
        if: steps.version.outputs.has_changes == 'true'
        run: |
          VERSION="${{ steps.version.outputs.new_version }}"
          RELEASE_DIR="release-package"
          DATE=$(date -u +"%Y-%m-%d")

          # Extract upstream info from index.json
          UPSTREAM_TS=$(jq -r '."x-upstream-timestamp" // "unknown"' docs/specifications/api/index.json)
          ENRICHED_VER=$(jq -r '."x-enriched-version" // "'$VERSION'"' docs/specifications/api/index.json)

          # Create ZIP filename
          ZIP_NAME="f5xc-api-specs-v${VERSION}.zip"

          echo "::notice::Creating release package: ${ZIP_NAME}"

          # Create release directory structure
          mkdir -p "$RELEASE_DIR/domains"

          # Copy master specification
          cp docs/specifications/api/openapi.json "$RELEASE_DIR/"

          # Convert JSON to YAML format
          python3 -c "
          import json
          import yaml

          with open('docs/specifications/api/openapi.json', 'r') as f:
              spec = json.load(f)

          with open('$RELEASE_DIR/openapi.yaml', 'w') as f:
              yaml.dump(spec, f, default_flow_style=False, allow_unicode=True, sort_keys=False)

          print('Created openapi.yaml')
          "

          # Copy domain specifications to domains/ subdirectory
          for spec_file in docs/specifications/api/*.json; do
            basename_f=$(basename "$spec_file")
            if [ "$basename_f" != "openapi.json" ] && [ "$basename_f" != "index.json" ]; then
              cp "$spec_file" "$RELEASE_DIR/domains/"
              echo "Copied domain: $basename_f"
            fi
          done

          # Copy metadata index
          cp docs/specifications/api/index.json "$RELEASE_DIR/"

          # Copy changelog
          cp CHANGELOG.md "$RELEASE_DIR/"

          # Process README template with placeholder substitution
          sed "s/{VERSION}/${UPSTREAM_TS}-${ENRICHED_VER}/g; s/{DATE}/${DATE}/g" \
            release/README.md > "$RELEASE_DIR/README.md"

          # Show package contents
          echo "::group::Package contents"
          find "$RELEASE_DIR" -type f | sort
          echo "::endgroup::"

          # Create ZIP package
          cd "$RELEASE_DIR"
          zip -r "../${ZIP_NAME}" .
          cd ..

          echo "zip_name=${ZIP_NAME}" >> "$GITHUB_ENV"
          echo "::notice::Package created: ${ZIP_NAME}"

      - name: Create release
        if: steps.version.outputs.has_changes == 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          VERSION="${{ steps.version.outputs.new_version }}"

          # Check if release already exists
          if gh release view "v$VERSION" >/dev/null 2>&1; then
            echo "Release v$VERSION already exists, skipping"
            exit 0
          fi

          # Create release with ZIP package
          gh release create "v$VERSION" \
            --title "API Specs v$VERSION" \
            --notes-file CHANGELOG.md \
            "${zip_name}" \
            docs/specifications/api/openapi.json \
            docs/specifications/api/index.json

          echo "::notice::Created release: v$VERSION"

  deploy-docs:
    name: Deploy Documentation
    needs: sync-and-enrich
    if: needs.sync-and-enrich.outputs.has_changes == 'true'
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Download docs artifact
        uses: actions/download-artifact@v4
        with:
          name: docs-site
          path: docs

      - name: Setup Pages
        uses: actions/configure-pages@v5

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v4
        with:
          path: docs

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

  # ==========================================================================
  # WORKFLOW MONITORING - Create issues for failures
  # ==========================================================================
  monitor-failures:
    name: Monitor Workflow Failures
    runs-on: ubuntu-latest
    needs: [check-updates, sync-and-enrich, deploy-docs]
    if: always()
    steps:
      - name: Check for failures
        id: check_failure
        run: |
          # Check if any job failed or was cancelled
          if [ "${{ needs.check-updates.result }}" = "failure" ] || \
             [ "${{ needs.sync-and-enrich.result }}" = "failure" ] || \
             [ "${{ needs.deploy-docs.result }}" = "failure" ] || \
             [ "${{ needs.check-updates.result }}" = "cancelled" ] || \
             [ "${{ needs.sync-and-enrich.result }}" = "cancelled" ] || \
             [ "${{ needs.deploy-docs.result }}" = "cancelled" ]; then
            echo "has_failure=true" >> "$GITHUB_OUTPUT"
            echo "::warning::Workflow failure detected - will create issue"
          else
            echo "has_failure=false" >> "$GITHUB_OUTPUT"
            echo "All jobs completed successfully"
          fi

      - name: Checkout repository
        if: steps.check_failure.outputs.has_failure == 'true'
        uses: actions/checkout@v6

      - name: Setup Python
        if: steps.check_failure.outputs.has_failure == 'true'
        uses: actions/setup-python@v6
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        if: steps.check_failure.outputs.has_failure == 'true'
        run: pip install -r requirements.txt

      - name: Ensure monitoring labels exist
        if: steps.check_failure.outputs.has_failure == 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: python scripts/ensure_labels.py

      - name: Analyze failures and create/update issues
        if: steps.check_failure.outputs.has_failure == 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          RUN_ID: ${{ github.run_id }}
          WORKFLOW_NAME: ${{ github.workflow }}
          TRIGGER_EVENT: ${{ github.event_name }}
          BRANCH: ${{ github.ref_name }}
          COMMIT_SHA: ${{ github.sha }}
          ACTOR: ${{ github.actor }}
          JOB_CHECK_UPDATES: ${{ needs.check-updates.result }}
          JOB_SYNC_ENRICH: ${{ needs.sync-and-enrich.result }}
          JOB_DEPLOY: ${{ needs.deploy-docs.result }}
        run: |
          python scripts/monitor_workflow.py \
            --run-id "$RUN_ID" \
            --workflow "$WORKFLOW_NAME" \
            --event "$TRIGGER_EVENT" \
            --branch "$BRANCH" \
            --commit "$COMMIT_SHA"
